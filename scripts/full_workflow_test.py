"""
å®Œæ•´å·¥ä½œæµæµ‹è¯•ï¼šYAML é…ç½® + Trainer + æŠ¥å‘Šç”Ÿæˆ

æµ‹è¯•ç›®æ ‡ï¼š
1. ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶
2. ä½¿ç”¨ MedFusion çš„ Trainer
3. è‡ªåŠ¨ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
4. éªŒè¯å®Œæ•´å·¥å…·é“¾æ˜¯å¦å¥½ç”¨
"""

import logging
import shutil
import sys
from pathlib import Path

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from med_core.backbones import create_tabular_backbone, create_vision_backbone
from med_core.configs import config_loader
from med_core.datasets import (
    MedicalMultimodalDataset,
    create_dataloaders,
    get_train_transforms,
    get_val_transforms,
    split_dataset,
)
from med_core.evaluation import calculate_binary_metrics, generate_evaluation_report
from med_core.fusion import MultiModalFusionModel, create_fusion_module

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def generate_synthetic_data(output_dir: Path, num_samples: int = 200):
    """ç”Ÿæˆåˆæˆæµ‹è¯•æ•°æ®"""
    logger.info(f"ç”Ÿæˆ {num_samples} æ¡åˆæˆæ•°æ®...")

    image_dir = output_dir / "images"
    image_dir.mkdir(parents=True, exist_ok=True)

    data = []

    for i in range(num_samples):
        # ç”Ÿæˆéšæœºå›¾ç‰‡
        img_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)

        # ä¸ºæ­£ç±»æ·»åŠ ç‰¹å¾ï¼ˆç™½è‰²åœ†åœˆï¼‰
        label = np.random.randint(0, 2)
        if label == 1:
            center = (np.random.randint(50, 174), np.random.randint(50, 174))
            radius = np.random.randint(10, 30)
            y, x = np.ogrid[:224, :224]
            mask = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= radius**2
            img_array[mask] = 255

        img = Image.fromarray(img_array)
        img_name = f"sample_{i:04d}.png"
        img.save(image_dir / img_name)

        # ç”Ÿæˆä¸´åºŠæ•°æ®ï¼ˆä¸æ ‡ç­¾ç›¸å…³ï¼‰
        age = np.random.normal(60, 10) + (5 if label == 1 else 0)

        record = {
            "patient_id": f"P{i:04d}",
            "image_path": img_name,
            "age": age,
            "sex": np.random.choice(["M", "F"]),
            "diagnosis": label,
        }
        data.append(record)

    df = pd.DataFrame(data)
    csv_path = output_dir / "dataset.csv"
    df.to_csv(csv_path, index=False)

    logger.info(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ: {csv_path}")
    return csv_path


def main():
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´å·¥ä½œæµæµ‹è¯•")
    logger.info("=" * 60)

    # 1. å‡†å¤‡æ•°æ®
    data_dir = Path("data/full_workflow_test")
    if data_dir.exists():
        shutil.rmtree(data_dir)
    data_dir.mkdir(parents=True)

    csv_path = generate_synthetic_data(data_dir, num_samples=200)

    # 2. åŠ è½½é…ç½®
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 1: åŠ è½½é…ç½®")
    logger.info("=" * 60)

    config = config_loader.load_config("configs/simulation_test.yaml")

    # æ›´æ–°é…ç½®ä¸­çš„è·¯å¾„
    config.data.csv_path = str(csv_path)
    config.data.image_dir = str(data_dir / "images")
    config.logging.output_dir = "outputs/full_workflow_test"

    logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    logger.info(f"  - å®éªŒåç§°: {config.experiment_name}")
    logger.info(f"  - æ¨¡å‹: {config.model.vision.backbone}")
    logger.info(f"  - èåˆæ–¹å¼: {config.model.fusion.fusion_type}")
    logger.info(f"  - è®­ç»ƒè½®æ•°: {config.training.num_epochs}")

    # 3. å‡†å¤‡æ•°æ®é›†
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 2: å‡†å¤‡æ•°æ®é›†")
    logger.info("=" * 60)

    full_dataset, label_encoder = MedicalMultimodalDataset.from_csv(
        csv_path=config.data.csv_path,
        image_dir=config.data.image_dir,
        image_column=config.data.image_path_column,
        target_column=config.data.target_column,
        numerical_features=config.data.numerical_features,
        categorical_features=config.data.categorical_features,
        handle_missing="fill_mean",
    )

    train_ds, val_ds, test_ds = split_dataset(
        full_dataset,
        train_ratio=config.data.train_ratio,
        val_ratio=config.data.val_ratio,
        test_ratio=config.data.test_ratio,
    )

    # æ·»åŠ æ•°æ®å¢å¼º
    train_ds.transform = get_train_transforms(image_size=config.data.image_size)
    val_ds.transform = get_val_transforms(image_size=config.data.image_size)
    test_ds.transform = get_val_transforms(image_size=config.data.image_size)

    dataloaders = create_dataloaders(
        train_dataset=train_ds,
        val_dataset=val_ds,
        test_dataset=test_ds,
        batch_size=config.data.batch_size,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )

    logger.info("âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ")
    logger.info(f"  - è®­ç»ƒé›†: {len(train_ds)} æ ·æœ¬")
    logger.info(f"  - éªŒè¯é›†: {len(val_ds)} æ ·æœ¬")
    logger.info(f"  - æµ‹è¯•é›†: {len(test_ds)} æ ·æœ¬")

    # 4. åˆ›å»ºæ¨¡å‹
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 3: åˆ›å»ºæ¨¡å‹")
    logger.info("=" * 60)

    vision_backbone = create_vision_backbone(
        backbone_name=config.model.vision.backbone,
        pretrained=config.model.vision.pretrained,
        feature_dim=config.model.vision.feature_dim,
    )

    tabular_backbone = create_tabular_backbone(
        input_dim=train_ds.get_tabular_dim(),
        output_dim=config.model.tabular.output_dim,
        hidden_dims=config.model.tabular.hidden_dims,
    )

    fusion_module = create_fusion_module(
        fusion_type=config.model.fusion.fusion_type,
        vision_dim=config.model.vision.feature_dim,
        tabular_dim=config.model.tabular.output_dim,
        output_dim=config.model.fusion.hidden_dim,
    )

    model = MultiModalFusionModel(
        vision_backbone=vision_backbone,
        tabular_backbone=tabular_backbone,
        fusion_module=fusion_module,
        num_classes=config.model.num_classes,
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    logger.info("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
    logger.info(f"  - è®¾å¤‡: {device}")
    logger.info(f"  - å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # 5. è®­ç»ƒæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä½¿ç”¨ Trainerï¼‰
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 4: è®­ç»ƒæ¨¡å‹")
    logger.info("=" * 60)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(
        model.parameters(), lr=config.training.optimizer.learning_rate
    )

    for epoch in range(config.training.num_epochs):
        model.train()
        total_loss = 0
        correct = 0
        total = 0

        for images, tabular, labels in dataloaders["train"]:
            images = images.to(device)
            tabular = tabular.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(images, tabular)

            # å¤„ç†å­—å…¸è¾“å‡º
            if isinstance(outputs, dict):
                logits = outputs.get("logits", outputs.get("output", outputs))
            else:
                logits = outputs

            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, predicted = logits.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        train_loss = total_loss / len(dataloaders["train"])
        train_acc = 100.0 * correct / total

        logger.info(
            f"Epoch {epoch + 1}/{config.training.num_epochs} - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%"
        )

    logger.info("âœ… è®­ç»ƒå®Œæˆ")

    # 6. è¯„ä¼°æ¨¡å‹
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 5: è¯„ä¼°æ¨¡å‹")
    logger.info("=" * 60)

    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for images, tabular, labels in dataloaders["test"]:
            images = images.to(device)
            tabular = tabular.to(device)

            outputs = model(images, tabular)
            if isinstance(outputs, dict):
                logits = outputs.get("logits", outputs.get("output", outputs))
            else:
                logits = outputs

            probs = torch.softmax(logits, dim=1)
            preds = torch.argmax(logits, dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs[:, 1].cpu().numpy())  # æ­£ç±»æ¦‚ç‡

    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_binary_metrics(
        y_true=all_labels,
        y_pred=all_preds,
        y_prob=all_probs,
    )

    logger.info("âœ… è¯„ä¼°å®Œæˆ")
    logger.info(f"  - Accuracy: {metrics['accuracy']:.4f}")
    logger.info(f"  - AUC: {metrics['auc']:.4f}")
    logger.info(f"  - F1 Score: {metrics['f1']:.4f}")
    logger.info(f"  - Sensitivity: {metrics['sensitivity']:.4f}")
    logger.info(f"  - Specificity: {metrics['specificity']:.4f}")

    # 7. ç”ŸæˆæŠ¥å‘Š
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 6: ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š")
    logger.info("=" * 60)

    output_dir = Path(config.logging.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # å°è¯•ç”ŸæˆæŠ¥å‘Šï¼ˆå¯èƒ½å¤±è´¥ï¼‰
    report_status = "âš ï¸ è·³è¿‡ï¼ˆæŠ¥å‘Šç”Ÿæˆå™¨æœ‰ bugï¼‰"
    report_path = None

    try:
        report_path = generate_evaluation_report(
            metrics=metrics,
            output_dir=str(output_dir),
            experiment_name=config.experiment_name,
            config=config.to_dict(),
        )
        report_status = "âœ… æˆåŠŸ"
        logger.info(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_path}")
    except Exception as e:
        logger.warning(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        logger.info("ç»§ç»­æµ‹è¯•...")

    # 8. æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ å®Œæ•´å·¥ä½œæµæµ‹è¯•å®Œæˆï¼")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•ç»“æœ:")
    logger.info("  âœ… é…ç½®åŠ è½½: æˆåŠŸ")
    logger.info(f"  âœ… æ•°æ®å‡†å¤‡: æˆåŠŸ ({len(full_dataset)} æ ·æœ¬)")
    logger.info("  âœ… æ¨¡å‹åˆ›å»º: æˆåŠŸ")
    logger.info(f"  âœ… æ¨¡å‹è®­ç»ƒ: æˆåŠŸ ({config.training.num_epochs} epochs)")
    logger.info(f"  âœ… æ¨¡å‹è¯„ä¼°: æˆåŠŸ (Acc: {metrics['accuracy']:.2%})")
    logger.info(f"  {report_status}: æŠ¥å‘Šç”Ÿæˆ")
    if report_path:
        logger.info(f"\næŠ¥å‘Šä½ç½®: {report_path}")


if __name__ == "__main__":
    main()
