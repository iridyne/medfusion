"""
ç®€åŒ–ç‰ˆæ¨¡æ‹Ÿæµ‹è¯• - ç›´æ¥æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½

ç›®æ ‡ï¼šç”¨æœ€ç®€å•çš„æ–¹å¼æµ‹è¯• MedFusion æ˜¯å¦èƒ½è·‘é€š
"""

import logging
import sys
import time
from pathlib import Path

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from torch.utils.data import DataLoader, Dataset

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from med_core.backbones import create_tabular_backbone, create_vision_backbone
from med_core.fusion import MultiModalFusionModel, create_fusion_module

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# æµ‹è¯•è®°å½•
test_log = []


def log_test(stage, success, time_taken, notes=""):
    """è®°å½•æµ‹è¯•ç»“æœ"""
    test_log.append(
        {
            "stage": stage,
            "success": success,
            "time": f"{time_taken:.2f}s",
            "notes": notes,
        }
    )
    status = "âœ…" if success else "âŒ"
    logger.info(f"{status} {stage} - {time_taken:.2f}s - {notes}")


def test_stage_1_data_generation():
    """é˜¶æ®µ 1: ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 1: ç”Ÿæˆæµ‹è¯•æ•°æ®")
    logger.info("=" * 60)
    start = time.time()

    try:
        # åˆ›å»ºç›®å½•
        data_dir = Path("data/simple_test")
        images_dir = data_dir / "images"
        images_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆ 100 å¼ å›¾ç‰‡
        records = []
        for i in range(100):
            # ç”Ÿæˆéšæœºå›¾ç‰‡
            img_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            img = Image.fromarray(img_array)
            img_path = images_dir / f"img_{i:03d}.png"
            img.save(img_path)

            # ç”Ÿæˆæ ‡ç­¾å’Œè¡¨æ ¼æ•°æ®
            label = i % 2
            records.append(
                {
                    "image_path": str(img_path),
                    "age": np.random.randint(20, 80),
                    "sex": np.random.choice([0, 1]),
                    "label": label,
                }
            )

        # ä¿å­˜ CSV
        df = pd.DataFrame(records)
        csv_path = data_dir / "data.csv"
        df.to_csv(csv_path, index=False)

        elapsed = time.time() - start
        log_test("æ•°æ®ç”Ÿæˆ", True, elapsed, f"ç”Ÿæˆ {len(df)} æ¡æ•°æ®")
        return data_dir, csv_path, df

    except Exception as e:
        elapsed = time.time() - start
        log_test("æ•°æ®ç”Ÿæˆ", False, elapsed, str(e))
        raise


def test_stage_2_create_model():
    """é˜¶æ®µ 2: åˆ›å»ºæ¨¡å‹"""
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 2: åˆ›å»ºæ¨¡å‹")
    logger.info("=" * 60)
    start = time.time()

    try:
        # åˆ›å»º vision backbone
        logger.info("åˆ›å»º ResNet18 backbone...")
        vision_backbone = create_vision_backbone(
            backbone_name="resnet18",
            pretrained=False,  # å¿«é€Ÿæµ‹è¯•ï¼Œä¸ç”¨é¢„è®­ç»ƒ
            feature_dim=512,  # ResNet18 è¾“å‡ºç»´åº¦
            attention_type="none",  # ç®€åŒ–æµ‹è¯•ï¼Œä¸ç”¨æ³¨æ„åŠ›
        )

        # åˆ›å»º tabular backbone
        logger.info("åˆ›å»º tabular backbone...")
        tabular_backbone = create_tabular_backbone(
            input_dim=2,  # age + sex
            hidden_dims=[16, 16],
            output_dim=16,
        )

        # åˆ›å»º fusion module
        logger.info("åˆ›å»º fusion module...")
        fusion_module = create_fusion_module(
            fusion_type="concatenate",
            vision_dim=512,  # ResNet18 è¾“å‡º
            tabular_dim=16,
        )

        # åˆ›å»ºå®Œæ•´æ¨¡å‹
        logger.info("ç»„è£…å®Œæ•´æ¨¡å‹...")
        model = MultiModalFusionModel(
            vision_backbone=vision_backbone,
            tabular_backbone=tabular_backbone,
            fusion_module=fusion_module,
            num_classes=2,
        )

        elapsed = time.time() - start
        log_test("æ¨¡å‹åˆ›å»º", True, elapsed, "ResNet18 + MLP + Concatenate")
        return model

    except Exception as e:
        elapsed = time.time() - start
        log_test("æ¨¡å‹åˆ›å»º", False, elapsed, str(e))
        raise


class SimpleDataset(Dataset):
    """ç®€å•çš„æ•°æ®é›†ç±»"""

    def __init__(self, df):
        self.df = df

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # åŠ è½½å›¾ç‰‡
        img = Image.open(row["image_path"]).convert("RGB")
        img_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float() / 255.0

        # è¡¨æ ¼æ•°æ®
        tabular = torch.tensor([row["age"] / 100.0, row["sex"]], dtype=torch.float32)

        # æ ‡ç­¾
        label = torch.tensor(row["label"], dtype=torch.long)

        return img_tensor, tabular, label


def test_stage_3_training():
    """é˜¶æ®µ 3: è®­ç»ƒæ¨¡å‹"""
    logger.info("\n" + "=" * 60)
    logger.info("é˜¶æ®µ 3: è®­ç»ƒæ¨¡å‹ï¼ˆ1 ä¸ª epochï¼‰")
    logger.info("=" * 60)
    start = time.time()

    try:
        # ç”Ÿæˆæ•°æ®
        data_dir, csv_path, df = test_stage_1_data_generation()

        # åˆ›å»ºæ¨¡å‹
        model = test_stage_2_create_model()

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataset = SimpleDataset(df)
        dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

        # è®¾ç½®è®­ç»ƒ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        logger.info("å¼€å§‹è®­ç»ƒ...")

        # è®­ç»ƒ 1 ä¸ª epoch
        model.train()
        total_loss = 0
        correct = 0
        total = 0

        for batch_idx, (images, tabular, labels) in enumerate(dataloader):
            images = images.to(device)
            tabular = tabular.to(device)
            labels = labels.to(device)

            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            outputs = model(images, tabular)

            # æ¨¡å‹å¯èƒ½è¿”å›å­—å…¸ï¼Œæå– logits
            if isinstance(outputs, dict):
                logits = outputs.get("logits", outputs.get("output", outputs))
            else:
                logits = outputs

            loss = criterion(logits, labels)

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = logits.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            if (batch_idx + 1) % 2 == 0:
                logger.info(
                    f"Batch {batch_idx + 1}/{len(dataloader)}, "
                    f"Loss: {loss.item():.4f}, "
                    f"Acc: {100.0 * correct / total:.2f}%"
                )

        avg_loss = total_loss / len(dataloader)
        accuracy = 100.0 * correct / total

        elapsed = time.time() - start
        log_test(
            "æ¨¡å‹è®­ç»ƒ",
            True,
            elapsed,
            f"Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%",
        )

        return model, avg_loss, accuracy

    except Exception as e:
        elapsed = time.time() - start
        log_test("æ¨¡å‹è®­ç»ƒ", False, elapsed, str(e))
        raise


def print_summary():
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)

    total_time = sum(float(t["time"].replace("s", "")) for t in test_log)
    success_count = sum(1 for t in test_log if t["success"])

    logger.info(f"\næ€»è€—æ—¶: {total_time:.2f} ç§’")
    logger.info(f"æˆåŠŸ: {success_count}/{len(test_log)}")

    logger.info("\nè¯¦ç»†ç»“æœ:")
    for t in test_log:
        status = "âœ…" if t["success"] else "âŒ"
        logger.info(f"  {status} {t['stage']}: {t['time']} - {t['notes']}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ MedFusion ç®€åŒ–æµ‹è¯•")
    logger.info("ç›®æ ‡ï¼šéªŒè¯æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦èƒ½è·‘é€š\n")

    try:
        # è¿è¡Œå®Œæ•´è®­ç»ƒæµ‹è¯•
        model, loss, acc = test_stage_3_training()

        logger.info("\nğŸ‰ æµ‹è¯•æˆåŠŸï¼MedFusion æ ¸å¿ƒåŠŸèƒ½å¯ç”¨")
        logger.info(f"æœ€ç»ˆç»“æœ: Loss={loss:.4f}, Accuracy={acc:.2f}%")

    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

    finally:
        print_summary()


if __name__ == "__main__":
    main()
