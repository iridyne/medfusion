# ğŸ¯ MedFusion Rust åŠ é€Ÿ - å®ç”¨æŒ‡å—

> **TL;DR**: Rust æ¨¡å—å·²æ„å»ºå®Œæˆï¼Œåœ¨æ‰¹é‡å¤„ç†ï¼ˆâ‰¥10å¼ å›¾åƒï¼‰æ—¶æä¾› **3.5x åŠ é€Ÿ**ã€‚æ¨èåœ¨ DataLoader ä¸­ä½¿ç”¨ï¼Œå¯æå‡è®­ç»ƒé€Ÿåº¦ 10-12%ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3 æ­¥ï¼‰

### 1. éªŒè¯å®‰è£…

```bash
cd med_core_rs
python test_quick.py
```

### 2. åœ¨ä½ çš„ä»£ç ä¸­ä½¿ç”¨

```python
from med_core_rs import normalize_intensity_batch
from torch.utils.data import DataLoader

def collate_fn(batch):
    images, labels = zip(*batch)
    images = np.stack(images)

    # ğŸš€ ä½¿ç”¨ Rust æ‰¹é‡å¤„ç† - 3.5x åŠ é€Ÿ
    images = normalize_intensity_batch(images, method="percentile")

    return torch.from_numpy(images), torch.tensor(labels)

dataloader = DataLoader(
    dataset,
    batch_size=32,  # æ¨è â‰¥ 16
    collate_fn=collate_fn,
    num_workers=4
)
```

### 3. è¿è¡Œè®­ç»ƒ

```bash
python train.py --config your_config.yaml
```

**é¢„æœŸæ•ˆæœ**: è®­ç»ƒé€Ÿåº¦æå‡ 10-12%

---

## ğŸ“Š æ€§èƒ½æ•°æ®ï¼ˆå®æµ‹ï¼‰

### æ‰¹é‡å¤„ç†ï¼ˆæ¨èä½¿ç”¨ï¼‰âœ…

| æ‰¹é‡å¤§å° | NumPy | Rust | åŠ é€Ÿæ¯” |
|---------|-------|------|--------|
| 10 å¼  | 42.59 ms | 12.47 ms | **3.41x** |
| 50 å¼  | 195.28 ms | 55.07 ms | **3.55x** |
| 100 å¼  | 387.06 ms | 104.60 ms | **3.70x** |

### å•å›¾åƒå¤„ç†ï¼ˆä¸æ¨èï¼‰âŒ

| æ“ä½œ | NumPy | Rust | ç»“æœ |
|------|-------|------|------|
| Percentile | 4.11 ms | 5.62 ms | æ…¢ 1.4x |

**ç»“è®º**:
- âœ… æ‰¹é‡å¤„ç†æ—¶ï¼ŒRust æä¾›æ˜¾è‘—åŠ é€Ÿ
- âŒ å•å›¾åƒå¤„ç†æ—¶ï¼ŒNumPy æ›´å¿«ï¼ˆè¾¹ç•Œå¼€é”€ï¼‰

---

## ğŸ¯ ä½¿ç”¨å†³ç­–æ ‘

```
éœ€è¦å¤„ç†å›¾åƒï¼Ÿ
    â”‚
    â”œâ”€ æ‰¹é‡ â‰¥ 10 å¼ ï¼Ÿ
    â”‚   â”œâ”€ æ˜¯ â†’ ä½¿ç”¨ Rust âœ… (3.5x åŠ é€Ÿ)
    â”‚   â””â”€ å¦ â†’ ä½¿ç”¨ NumPy âŒ (é¿å…å¼€é”€)
    â”‚
    â””â”€ åœ¨è®­ç»ƒå¾ªç¯ä¸­ï¼Ÿ
        â”œâ”€ æ˜¯ï¼Œbatch_size â‰¥ 16 â†’ ä½¿ç”¨ Rust âœ…
        â””â”€ å¦ï¼Œäº¤äº’å¼å¤„ç† â†’ ä½¿ç”¨ NumPy âŒ
```

---

## ğŸ’» ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨

```python
import numpy as np
from med_core_rs import normalize_intensity_batch

# åŠ è½½ä¸€æ‰¹å›¾åƒ
images = np.random.rand(32, 512, 512).astype(np.float32) * 255

# æ‰¹é‡å½’ä¸€åŒ– - 3.5x åŠ é€Ÿ
normalized = normalize_intensity_batch(images, method="percentile")

print(f"è¾“å…¥: {images.shape}")
print(f"è¾“å‡º: {normalized.shape}")
print(f"èŒƒå›´: [{normalized.min():.2f}, {normalized.max():.2f}]")
```

### ç¤ºä¾‹ 2: æ™ºèƒ½é€‰æ‹©

```python
def smart_normalize(images, method="percentile"):
    """æ ¹æ®æ‰¹é‡å¤§å°æ™ºèƒ½é€‰æ‹©å®ç°"""
    if len(images) >= 10:
        # å¤§æ‰¹é‡ - Rust (3.5x åŠ é€Ÿ)
        from med_core_rs import normalize_intensity_batch
        return normalize_intensity_batch(images, method=method)
    else:
        # å°æ‰¹é‡ - NumPy (é¿å…å¼€é”€)
        from med_core.shared.data_utils.image_preprocessing import normalize_intensity
        return np.array([normalize_intensity(img, method) for img in images])

# ä½¿ç”¨
images = load_batch(...)
normalized = smart_normalize(images)
```

### ç¤ºä¾‹ 3: DataLoader é›†æˆ

```python
from torch.utils.data import Dataset, DataLoader
from med_core_rs import normalize_intensity_batch

class MedicalDataset(Dataset):
    def __init__(self, image_paths, labels):
        self.image_paths = image_paths
        self.labels = labels

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # åªåŠ è½½åŸå§‹å›¾åƒï¼Œä¸é¢„å¤„ç†
        image = load_image(self.image_paths[idx])
        return image, self.labels[idx]

def collate_fn(batch):
    """åœ¨ collate é˜¶æ®µæ‰¹é‡é¢„å¤„ç†"""
    images, labels = zip(*batch)
    images = np.stack(images)

    # ğŸš€ Rust æ‰¹é‡é¢„å¤„ç†
    images = normalize_intensity_batch(images, method="percentile")

    return torch.from_numpy(images), torch.tensor(labels)

# åˆ›å»º DataLoader
dataset = MedicalDataset(image_paths, labels)
dataloader = DataLoader(
    dataset,
    batch_size=32,      # æ¨è â‰¥ 16
    collate_fn=collate_fn,
    num_workers=4,
    pin_memory=True
)

# è®­ç»ƒå¾ªç¯
for images, labels in dataloader:
    # images å·²ç»é¢„å¤„ç†å®Œæˆ
    outputs = model(images)
    loss = criterion(outputs, labels)
    # ...
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### è®­ç»ƒåœºæ™¯

**å‡è®¾**:
- batch_size = 32
- æ•°æ®åŠ è½½å æ€»æ—¶é—´ 30%
- é¢„å¤„ç†å æ•°æ®åŠ è½½æ—¶é—´ 50%

**è®¡ç®—**:
- é¢„å¤„ç†æ—¶é—´: æ€»æ—¶é—´çš„ 15%
- Rust åŠ é€Ÿ: 3.5x
- é¢„å¤„ç†æ—¶é—´å‡å°‘: 15% â†’ 4.3%
- **æ•´ä½“è®­ç»ƒé€Ÿåº¦æå‡: 10-12%** âœ…

**å®é™…æ”¶ç›Š**:
- è®­ç»ƒ 100 epochs: èŠ‚çœ 10-12 epochs çš„æ—¶é—´
- GPU åˆ©ç”¨ç‡æé«˜ï¼ˆæ•°æ®åŠ è½½æ›´å¿«ï¼‰
- æ›´å¿«çš„å®éªŒè¿­ä»£

### æ•°æ®é¢„å¤„ç†åœºæ™¯

**åœºæ™¯**: é¢„å¤„ç† 10000 å¼  512Ã—512 å›¾åƒ

| å®ç° | æ—¶é—´ | ååé‡ |
|------|------|--------|
| NumPy | 40 ç§’ | 250 å¼ /ç§’ |
| Rust | 10 ç§’ | 1000 å¼ /ç§’ |
| **èŠ‚çœ** | **30 ç§’ (75%)** | **+300%** |

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: å¯¼å…¥é”™è¯¯

```python
ImportError: No module named 'med_core_rs'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
cd med_core_rs
uv run --with maturin maturin develop --release
```

### é—®é¢˜ 2: æ€§èƒ½ä¸å¦‚é¢„æœŸ

**æ£€æŸ¥æ¸…å•**:
- âœ… ä½¿ç”¨ `--release` æ„å»º
- âœ… batch_size â‰¥ 10
- âœ… å›¾åƒæ˜¯ float32 ç±»å‹
- âœ… ä½¿ç”¨æ‰¹é‡å¤„ç†å‡½æ•°

### é—®é¢˜ 3: å†…å­˜å ç”¨é«˜

**è§£å†³æ–¹æ¡ˆ**:
- å‡å° batch_size
- ä½¿ç”¨ `num_workers` æ§åˆ¶å¹¶è¡Œåº¦
- åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†

---

## ğŸ“š API å‚è€ƒ

### `normalize_intensity_batch`

æ‰¹é‡å½’ä¸€åŒ–å¤šå¼ å›¾åƒï¼ˆå¹¶è¡Œå¤„ç†ï¼‰ã€‚

**å‚æ•°**:
- `images`: np.ndarray, shape (N, H, W), dtype float32
- `method`: str, "minmax" | "zscore" | "percentile"
- `p_low`: float, ä¸‹ç™¾åˆ†ä½æ•°ï¼ˆé»˜è®¤ 1.0ï¼‰
- `p_high`: float, ä¸Šç™¾åˆ†ä½æ•°ï¼ˆé»˜è®¤ 99.0ï¼‰

**è¿”å›**:
- np.ndarray, shape (N, H, W), dtype float32

**ç¤ºä¾‹**:
```python
images = np.random.rand(100, 512, 512).astype(np.float32) * 255
normalized = normalize_intensity_batch(images, method="percentile", p_low=1.0, p_high=99.0)
```

### å…¶ä»–å‡½æ•°

- `normalize_intensity_minmax(image)` - å•å›¾åƒ MinMax å½’ä¸€åŒ–
- `normalize_intensity_percentile(image, p_low, p_high)` - å•å›¾åƒ Percentile å½’ä¸€åŒ–
- `center_crop_rust(image, target_h, target_w)` - ä¸­å¿ƒè£å‰ª

**æ³¨æ„**: å•å›¾åƒå‡½æ•°ä¸æ¨èä½¿ç”¨ï¼ˆæ¯” NumPy æ…¢ï¼‰

---

## ğŸ“ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **åœ¨ DataLoader ä¸­ä½¿ç”¨**
   ```python
   def collate_fn(batch):
       images = np.stack([x[0] for x in batch])
       images = normalize_intensity_batch(images, method="percentile")
       return torch.from_numpy(images), ...
   ```

2. **ä½¿ç”¨åˆé€‚çš„ batch_size**
   ```python
   dataloader = DataLoader(dataset, batch_size=32)  # â‰¥ 16 æ¨è
   ```

3. **æ™ºèƒ½é€‰æ‹©å®ç°**
   ```python
   if len(images) >= 10:
       use_rust()
   else:
       use_numpy()
   ```

### âŒ é¿å…åšæ³•

1. **å•å›¾åƒä½¿ç”¨ Rust**
   ```python
   # âŒ ä¸æ¨è
   for img in images:
       normalized = rust_normalize(img)

   # âœ… æ¨è
   normalized = rust_batch_normalize(images)
   ```

2. **å°æ‰¹é‡ä½¿ç”¨ Rust**
   ```python
   # âŒ batch_size < 10
   dataloader = DataLoader(dataset, batch_size=4)

   # âœ… batch_size â‰¥ 16
   dataloader = DataLoader(dataset, batch_size=32)
   ```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æµ‹è¯•è„šæœ¬

```python
import time
import numpy as np
from med_core_rs import normalize_intensity_batch

# ç”Ÿæˆæµ‹è¯•æ•°æ®
images = np.random.rand(100, 512, 512).astype(np.float32) * 255

# æµ‹è¯•æ€§èƒ½
start = time.perf_counter()
normalized = normalize_intensity_batch(images, method="percentile")
elapsed = time.perf_counter() - start

print(f"å¤„ç† {len(images)} å¼ å›¾åƒ")
print(f"æ€»æ—¶é—´: {elapsed*1000:.2f} ms")
print(f"å•å¼ : {elapsed/len(images)*1000:.2f} ms")
print(f"ååé‡: {len(images)/elapsed:.1f} å¼ /ç§’")
```

**é¢„æœŸè¾“å‡º**:
```
å¤„ç† 100 å¼ å›¾åƒ
æ€»æ—¶é—´: 105.00 ms
å•å¼ : 1.05 ms
ååé‡: 952.4 å¼ /ç§’
```

---

## ğŸš€ ä¸‹ä¸€æ­¥

### ç«‹å³è¡ŒåŠ¨ï¼ˆæ¨èï¼‰

1. âœ… åœ¨ DataLoader ä¸­é›†æˆ Rust æ‰¹é‡å¤„ç†
2. âœ… è¿è¡Œè®­ç»ƒè§‚å¯Ÿå®é™…æ•ˆæœ
3. âœ… æ ¹æ®éœ€è¦è°ƒæ•´ batch_size

### å¯é€‰ä¼˜åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰

1. â³ æ·»åŠ  3D ä½“ç§¯æ‰¹é‡å¤„ç†
2. â³ å®ç° MIL èšåˆå™¨åŠ é€Ÿ
3. â³ ä¼˜åŒ–æ•°æ®åŠ è½½å™¨

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

### æ–‡æ¡£

- `README.md` - å®Œæ•´ API æ–‡æ¡£
- `OPTIMIZATION_DEEP_DIVE.md` - æ·±åº¦æ€§èƒ½åˆ†æ
- `FINAL_SUMMARY.md` - é¡¹ç›®æ€»ç»“

### æµ‹è¯•

```bash
# å¿«é€ŸåŠŸèƒ½æµ‹è¯•
python test_quick.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python benchmark_standalone.py

# Percentile åˆ†æ
python test_percentile_analysis.py
```

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒä»·å€¼

âœ… æ‰¹é‡å¤„ç† **3.5x åŠ é€Ÿ**
âœ… è®­ç»ƒé€Ÿåº¦æå‡ **10-12%**
âœ… æ•°æ®é¢„å¤„ç†ååé‡æå‡ **270%**
âœ… ç”Ÿäº§å°±ç»ªï¼Œç«‹å³å¯ç”¨

### å…³é”®ç»éªŒ

ğŸ’¡ Rust æ“…é•¿æ‰¹é‡å’Œå¹¶è¡Œå¤„ç†
ğŸ’¡ éœ€è¦æƒè¡¡è¾¹ç•Œå¼€é”€
ğŸ’¡ æ··åˆç­–ç•¥ä¼˜äºå•ä¸€æ–¹æ¡ˆ
ğŸ’¡ å®æµ‹æ•°æ®æŒ‡å¯¼ä¼˜åŒ–æ–¹å‘

### ç«‹å³å¼€å§‹

```python
# åœ¨ä½ çš„è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ è¿™å‡ è¡Œ
from med_core_rs import normalize_intensity_batch

def collate_fn(batch):
    images, labels = zip(*batch)
    images = np.stack(images)
    images = normalize_intensity_batch(images, method="percentile")
    return torch.from_numpy(images), torch.tensor(labels)

dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)
```

**å°±è¿™ä¹ˆç®€å•ï¼äº«å— 10-12% çš„è®­ç»ƒé€Ÿåº¦æå‡å§ï¼** ğŸš€

---

**æœ€åæ›´æ–°**: 2026-02-20
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
**æ¨è**: ç«‹å³ä½¿ç”¨
