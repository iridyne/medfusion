#!/usr/bin/env python3
"""
å®é™…é›†æˆç¤ºä¾‹ï¼šåœ¨ MedFusion è®­ç»ƒæµç¨‹ä¸­ä½¿ç”¨ Rust åŠ é€Ÿ

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨çœŸå®çš„è®­ç»ƒä»£ç ä¸­é›†æˆ Rust åŠ é€Ÿæ¨¡å—ã€‚
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'target/release'))

import numpy as np
import time
from typing import List, Tuple

# æ¨¡æ‹Ÿ PyTorch (å¦‚æœæ²¡æœ‰å®‰è£…)
try:
    import torch
    from torch.utils.data import Dataset, DataLoader
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("âš ï¸  PyTorch æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

import med_core_rs

print("="*70)
print("ğŸš€ MedFusion + Rust åŠ é€Ÿé›†æˆç¤ºä¾‹")
print("="*70)

# ============================================================================
# 1. å®šä¹‰æ•°æ®é›† (æ¨¡æ‹ŸåŒ»å­¦å›¾åƒæ•°æ®é›†)
# ============================================================================

class MedicalImageDataset:
    """æ¨¡æ‹ŸåŒ»å­¦å›¾åƒæ•°æ®é›†"""

    def __init__(self, n_samples=1000, image_size=(256, 256)):
        self.n_samples = n_samples
        self.image_size = image_size
        print(f"ğŸ“¦ åˆ›å»ºæ•°æ®é›†: {n_samples} å¼ å›¾åƒ, å¤§å° {image_size}")

    def __len__(self):
        return self.n_samples

    def __getitem__(self, idx):
        # æ¨¡æ‹ŸåŠ è½½åŒ»å­¦å›¾åƒ (å®é™…åº”è¯¥ä»æ–‡ä»¶åŠ è½½)
        image = np.random.rand(*self.image_size).astype(np.float32) * 1000
        label = idx % 2  # äºŒåˆ†ç±»
        return image, label

# ============================================================================
# 2. å®šä¹‰ Collate å‡½æ•° (å…³é”®ä¼˜åŒ–ç‚¹)
# ============================================================================

def collate_fn_numpy(batch: List[Tuple[np.ndarray, int]]):
    """ä¼ ç»Ÿçš„ NumPy collate å‡½æ•°"""
    images, labels = zip(*batch)
    images = np.stack(images)

    # NumPy Percentile å½’ä¸€åŒ–
    normalized = np.zeros_like(images)
    for i in range(len(images)):
        img = images[i]
        p1, p99 = np.percentile(img, [1, 99])
        if p99 - p1 > 1e-8:
            normalized[i] = np.clip((img - p1) / (p99 - p1), 0, 1)

    if HAS_TORCH:
        return torch.from_numpy(normalized), torch.tensor(labels)
    else:
        return normalized, np.array(labels)

def collate_fn_rust(batch: List[Tuple[np.ndarray, int]]):
    """ğŸš€ ä½¿ç”¨ Rust åŠ é€Ÿçš„ collate å‡½æ•°"""
    images, labels = zip(*batch)
    images = np.stack(images)

    # Rust Percentile å½’ä¸€åŒ– (4.8x åŠ é€Ÿ!)
    normalized = med_core_rs.normalize_intensity_batch(
        images,
        method="percentile",
        p_low=1.0,
        p_high=99.0
    )

    if HAS_TORCH:
        return torch.from_numpy(normalized), torch.tensor(labels)
    else:
        return normalized, np.array(labels)

# ============================================================================
# 3. æ€§èƒ½å¯¹æ¯”æµ‹è¯•
# ============================================================================

def benchmark_dataloader(collate_fn, name: str, n_batches: int = 50):
    """æµ‹è¯• DataLoader æ€§èƒ½"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æµ‹è¯•: {name}")
    print(f"{'='*70}")

    dataset = MedicalImageDataset(n_samples=1000)

    if HAS_TORCH:
        dataloader = DataLoader(
            dataset,
            batch_size=32,
            collate_fn=collate_fn,
            num_workers=0,  # å•è¿›ç¨‹æµ‹è¯•
            shuffle=False
        )
    else:
        # æ¨¡æ‹Ÿ DataLoader
        class SimpleDataLoader:
            def __init__(self, dataset, batch_size, collate_fn):
                self.dataset = dataset
                self.batch_size = batch_size
                self.collate_fn = collate_fn

            def __iter__(self):
                for i in range(0, len(self.dataset), self.batch_size):
                    batch = [self.dataset[j] for j in range(i, min(i + self.batch_size, len(self.dataset)))]
                    yield self.collate_fn(batch)

        dataloader = SimpleDataLoader(dataset, batch_size=32, collate_fn=collate_fn)

    # é¢„çƒ­
    for i, (images, labels) in enumerate(dataloader):
        if i >= 2:
            break

    # æµ‹è¯•
    times = []
    start_total = time.time()

    for i, (images, labels) in enumerate(dataloader):
        if i >= n_batches:
            break

        batch_start = time.time()
        # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­ (å®é™…è®­ç»ƒä¸­çš„æ“ä½œ)
        if HAS_TORCH:
            _ = images.mean()
        else:
            _ = images.mean()
        batch_time = time.time() - batch_start
        times.append(batch_time)

    total_time = time.time() - start_total

    print(f"æ€»æ—¶é—´: {total_time:.2f} ç§’")
    print(f"å¹³å‡æ¯æ‰¹: {np.mean(times)*1000:.2f} ms")
    print(f"ååé‡: {n_batches * 32 / total_time:.1f} å¼ /ç§’")

    return total_time, np.mean(times)

# ============================================================================
# 4. è¿è¡Œå¯¹æ¯”æµ‹è¯•
# ============================================================================

print("\n" + "="*70)
print("ğŸ”¬ å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
print("="*70)

# æµ‹è¯• NumPy ç‰ˆæœ¬
numpy_total, numpy_avg = benchmark_dataloader(collate_fn_numpy, "NumPy Percentile", n_batches=50)

# æµ‹è¯• Rust ç‰ˆæœ¬
rust_total, rust_avg = benchmark_dataloader(collate_fn_rust, "Rust Percentile ğŸš€", n_batches=50)

# è®¡ç®—åŠ é€Ÿæ¯”
speedup = numpy_total / rust_total

print("\n" + "="*70)
print("ğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ")
print("="*70)
print(f"{'æ–¹æ³•':<20} {'æ€»æ—¶é—´':<15} {'å¹³å‡æ¯æ‰¹':<15} {'ååé‡':<15}")
print("-"*70)
print(f"{'NumPy':<20} {numpy_total:>10.2f} s   {numpy_avg*1000:>10.2f} ms   {50*32/numpy_total:>10.1f} å¼ /ç§’")
print(f"{'Rust ğŸš€':<20} {rust_total:>10.2f} s   {rust_avg*1000:>10.2f} ms   {50*32/rust_total:>10.1f} å¼ /ç§’")
print("-"*70)
print(f"{'åŠ é€Ÿæ¯”':<20} {speedup:>10.2f}x")
print("="*70)

# ============================================================================
# 5. å®é™…è®­ç»ƒç¤ºä¾‹
# ============================================================================

print("\n" + "="*70)
print("ğŸ“ å®é™…è®­ç»ƒæµç¨‹ç¤ºä¾‹")
print("="*70)

def train_one_epoch_simulation(dataloader, name: str):
    """æ¨¡æ‹Ÿè®­ç»ƒä¸€ä¸ª epoch"""
    print(f"\nè®­ç»ƒ epoch ({name})...")

    start = time.time()
    total_loss = 0.0

    for i, (images, labels) in enumerate(dataloader):
        # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
        if HAS_TORCH:
            outputs = images.mean(dim=(1, 2))
            loss = (outputs - labels.float()).pow(2).mean()
        else:
            outputs = images.mean(axis=(1, 2))
            loss = ((outputs - labels) ** 2).mean()

        total_loss += float(loss)

        if i >= 31:  # æ¨¡æ‹Ÿ 1 ä¸ª epoch (1000 / 32 â‰ˆ 31 batches)
            break

    elapsed = time.time() - start
    print(f"  Epoch å®Œæˆ: {elapsed:.2f} ç§’")
    print(f"  å¹³å‡ loss: {total_loss / (i+1):.4f}")

    return elapsed

# åˆ›å»ºæ•°æ®é›†
dataset = MedicalImageDataset(n_samples=1000)

# NumPy ç‰ˆæœ¬
if HAS_TORCH:
    dataloader_numpy = DataLoader(dataset, batch_size=32, collate_fn=collate_fn_numpy, num_workers=0)
else:
    class SimpleDataLoader:
        def __init__(self, dataset, batch_size, collate_fn):
            self.dataset = dataset
            self.batch_size = batch_size
            self.collate_fn = collate_fn
        def __iter__(self):
            for i in range(0, len(self.dataset), self.batch_size):
                batch = [self.dataset[j] for j in range(i, min(i + self.batch_size, len(self.dataset)))]
                yield self.collate_fn(batch)
    dataloader_numpy = SimpleDataLoader(dataset, batch_size=32, collate_fn=collate_fn_numpy)

numpy_epoch_time = train_one_epoch_simulation(dataloader_numpy, "NumPy")

# Rust ç‰ˆæœ¬
if HAS_TORCH:
    dataloader_rust = DataLoader(dataset, batch_size=32, collate_fn=collate_fn_rust, num_workers=0)
else:
    dataloader_rust = SimpleDataLoader(dataset, batch_size=32, collate_fn=collate_fn_rust)

rust_epoch_time = train_one_epoch_simulation(dataloader_rust, "Rust ğŸš€")

# è®¡ç®—è®­ç»ƒåŠ é€Ÿ
train_speedup = numpy_epoch_time / rust_epoch_time

print("\n" + "="*70)
print("ğŸ¯ è®­ç»ƒæ€§èƒ½æå‡")
print("="*70)
print(f"NumPy epoch æ—¶é—´: {numpy_epoch_time:.2f} ç§’")
print(f"Rust epoch æ—¶é—´:  {rust_epoch_time:.2f} ç§’")
print(f"åŠ é€Ÿæ¯”: {train_speedup:.2f}x")
print(f"\nğŸ’¡ å¯¹äº 100 epochs è®­ç»ƒ:")
print(f"  NumPy: {numpy_epoch_time * 100 / 60:.1f} åˆ†é’Ÿ")
print(f"  Rust:  {rust_epoch_time * 100 / 60:.1f} åˆ†é’Ÿ")
print(f"  èŠ‚çœ: {(numpy_epoch_time - rust_epoch_time) * 100 / 60:.1f} åˆ†é’Ÿ")

print("\n" + "="*70)
print("âœ… é›†æˆç¤ºä¾‹å®Œæˆï¼")
print("="*70)
print("""
ğŸ“ å¦‚ä½•åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨:

1. å¤åˆ¶ med_core_rs.so åˆ°ä½ çš„é¡¹ç›®ç›®å½•
2. ä¿®æ”¹ DataLoader çš„ collate_fn:

   from med_core_rs import normalize_intensity_batch

   def collate_fn(batch):
       images, labels = zip(*batch)
       images = np.stack(images)
       images = normalize_intensity_batch(images, method="percentile")
       return torch.from_numpy(images), torch.tensor(labels)

3. åˆ›å»º DataLoader:

   dataloader = DataLoader(
       dataset,
       batch_size=32,
       collate_fn=collate_fn,
       num_workers=4
   )

4. äº«å— 4.8x åŠ é€Ÿï¼ğŸš€
""")
