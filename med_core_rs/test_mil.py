#!/usr/bin/env python3
"""
Test MIL aggregation functions
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'target/release'))

import numpy as np
import time

try:
    import med_core_rs
    print("âœ… med_core_rs æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ— æ³•åŠ è½½ med_core_rs: {e}")
    sys.exit(1)

print("\n" + "="*60)
print("ğŸ§ª MIL èšåˆå™¨åŠŸèƒ½æµ‹è¯•")
print("="*60)

# Test 1: Max pooling
print("\n[æµ‹è¯• 1] Max Pooling MIL")
instances = np.array([
    [1.0, 2.0, 3.0, 4.0],
    [5.0, 1.0, 2.0, 3.0],
    [2.0, 4.0, 1.0, 5.0],
], dtype=np.float32)
print(f"è¾“å…¥å®ä¾‹: {instances.shape}")

result = med_core_rs.max_pooling_mil(instances)
print(f"Max pooling ç»“æœ: {result}")
expected = np.array([5.0, 4.0, 3.0, 5.0])
assert np.allclose(result, expected), f"æœŸæœ› {expected}, å¾—åˆ° {result}"
print("âœ… Max pooling æ­£ç¡®")

# Test 2: Mean pooling
print("\n[æµ‹è¯• 2] Mean Pooling MIL")
instances = np.array([
    [1.0, 2.0],
    [3.0, 4.0],
    [5.0, 6.0],
], dtype=np.float32)

result = med_core_rs.mean_pooling_mil(instances)
print(f"Mean pooling ç»“æœ: {result}")
expected = np.array([3.0, 4.0])
assert np.allclose(result, expected), f"æœŸæœ› {expected}, å¾—åˆ° {result}"
print("âœ… Mean pooling æ­£ç¡®")

# Test 3: Attention MIL
print("\n[æµ‹è¯• 3] Attention MIL")
instances = np.array([
    [1.0, 2.0],
    [3.0, 4.0],
    [5.0, 6.0],
], dtype=np.float32)
attention_weights = np.array([[0.5], [0.3], [0.2]], dtype=np.float32)

result = med_core_rs.attention_mil(instances, attention_weights)
print(f"Attention MIL ç»“æœ: {result}")
# Expected: 0.5*[1,2] + 0.3*[3,4] + 0.2*[5,6] = [2.4, 3.4]
expected = np.array([2.4, 3.4])
assert np.allclose(result, expected), f"æœŸæœ› {expected}, å¾—åˆ° {result}"
print("âœ… Attention MIL æ­£ç¡®")

# Test 4: Batch processing
print("\n[æµ‹è¯• 4] æ‰¹é‡ MIL èšåˆ")
n_bags = 100
bags = [np.random.rand(np.random.randint(10, 50), 512).astype(np.float32)
        for _ in range(n_bags)]

print(f"æ‰¹é‡å¤§å°: {n_bags} bags")
print(f"ç‰¹å¾ç»´åº¦: 512")

# Max pooling
start = time.time()
result_max = med_core_rs.batch_mil_aggregation(bags, method="max")
time_max = time.time() - start
print(f"Max pooling: {time_max*1000:.2f} ms ({n_bags/time_max:.1f} bags/ç§’)")
assert result_max.shape == (n_bags, 512), f"å½¢çŠ¶ä¸åŒ¹é…: {result_max.shape}"

# Mean pooling
start = time.time()
result_mean = med_core_rs.batch_mil_aggregation(bags, method="mean")
time_mean = time.time() - start
print(f"Mean pooling: {time_mean*1000:.2f} ms ({n_bags/time_mean:.1f} bags/ç§’)")
assert result_mean.shape == (n_bags, 512), f"å½¢çŠ¶ä¸åŒ¹é…: {result_mean.shape}"

print("âœ… æ‰¹é‡å¤„ç†æ­£ç¡®")

# Test 5: Performance comparison
print("\n[æµ‹è¯• 5] æ€§èƒ½å¯¹æ¯” (Rust vs NumPy)")
n_bags = 200
bags = [np.random.rand(np.random.randint(20, 100), 512).astype(np.float32)
        for _ in range(n_bags)]

# Rust batch processing
start = time.time()
rust_result = med_core_rs.batch_mil_aggregation(bags, method="max")
rust_time = time.time() - start

# NumPy processing
def numpy_batch_max(bags):
    return np.array([bag.max(axis=0) for bag in bags])

start = time.time()
numpy_result = numpy_batch_max(bags)
numpy_time = time.time() - start

speedup = numpy_time / rust_time
print(f"Rust æ‰¹é‡å¤„ç†: {rust_time*1000:.2f} ms ({n_bags/rust_time:.1f} bags/ç§’)")
print(f"NumPy æ‰¹é‡å¤„ç†: {numpy_time*1000:.2f} ms ({n_bags/numpy_time:.1f} bags/ç§’)")
print(f"ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")

# Verify correctness
max_diff = np.abs(rust_result - numpy_result).max()
print(f"æœ€å¤§å·®å¼‚: {max_diff:.6f}")
assert max_diff < 1e-5, "ç»“æœä¸åŒ¹é…"
print("âœ… ç»“æœæ­£ç¡®æ€§éªŒè¯é€šè¿‡")

print("\n" + "="*60)
print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
print("="*60)

print("\nğŸ“Š æ€§èƒ½æ€»ç»“:")
print(f"  - Max pooling (100 bags): {time_max*1000:.1f} ms")
print(f"  - Mean pooling (100 bags): {time_mean*1000:.1f} ms")
print(f"  - ååé‡: {n_bags/rust_time:.1f} bags/ç§’")
print(f"  - ç›¸æ¯” NumPy åŠ é€Ÿ: {speedup:.2f}x")
