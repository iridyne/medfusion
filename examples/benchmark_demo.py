"""
æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨åŸºå‡†æµ‹è¯•å·¥å…·æ¥æµ‹é‡å’Œæ¯”è¾ƒæ€§èƒ½ã€‚
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


def demo_simple_benchmark():
    """æ¼”ç¤ºç®€å•çš„åŸºå‡†æµ‹è¯•"""
    print("=" * 60)
    print("ç®€å•åŸºå‡†æµ‹è¯•æ¼”ç¤º")
    print("=" * 60)

    # æ¨¡æ‹Ÿä¸¤ä¸ªä¸åŒçš„å®ç°
    def slow_function():
        """æ…¢é€Ÿå®ç°"""
        time.sleep(0.001)
        return sum(range(1000))

    def fast_function():
        """å¿«é€Ÿå®ç°"""
        return sum(range(1000))

    # æµ‹è¯•æ…¢é€Ÿå®ç°
    print("\n1. æµ‹è¯•æ…¢é€Ÿå®ç°:")
    start = time.time()
    for _ in range(100):
        slow_function()
    slow_time = time.time() - start
    print(f"   è€—æ—¶: {slow_time:.3f}s")
    print(f"   ååé‡: {100/slow_time:.1f} ops/s")

    # æµ‹è¯•å¿«é€Ÿå®ç°
    print("\n2. æµ‹è¯•å¿«é€Ÿå®ç°:")
    start = time.time()
    for _ in range(100):
        fast_function()
    fast_time = time.time() - start
    print(f"   è€—æ—¶: {fast_time:.3f}s")
    print(f"   ååé‡: {100/fast_time:.1f} ops/s")

    # æ¯”è¾ƒ
    speedup = slow_time / fast_time
    print(f"\n3. åŠ é€Ÿæ¯”: {speedup:.1f}x")


def demo_benchmark_suite():
    """æ¼”ç¤ºåŸºå‡†æµ‹è¯•å¥—ä»¶"""
    print("\n" + "=" * 60)
    print("åŸºå‡†æµ‹è¯•å¥—ä»¶æ¼”ç¤º")
    print("=" * 60)

    print("\nåŸºå‡†æµ‹è¯•å¥—ä»¶çš„åŠŸèƒ½:")
    print("  â€¢ ç®¡ç†å¤šä¸ªåŸºå‡†æµ‹è¯•")
    print("  â€¢ è‡ªåŠ¨è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    print("  â€¢ ä¿å­˜ç»“æœåˆ° JSON")
    print("  â€¢ ä¸åŸºçº¿æ¯”è¾ƒ")
    print("  â€¢ æ£€æµ‹æ€§èƒ½å›å½’")

    print("\nä½¿ç”¨ç¤ºä¾‹:")
    code = '''
from med_core.utils.benchmark import BenchmarkSuite, PerformanceBenchmark

# 1. åˆ›å»ºæµ‹è¯•å¥—ä»¶
suite = BenchmarkSuite(name="v0.2.0")

# 2. æ·»åŠ åŸºå‡†æµ‹è¯•
def test_model_inference():
    benchmark = PerformanceBenchmark("model_inference")
    return benchmark.run(lambda: model(input))

suite.add_benchmark("model_inference", test_model_inference)

# 3. è¿è¡Œæ‰€æœ‰æµ‹è¯•
results = suite.run_all()

# 4. ä¿å­˜ç»“æœ
suite.save_results("baseline.json")

# 5. ä¸åŸºçº¿æ¯”è¾ƒ
suite.compare_with("baseline.json")
'''
    print(code)


def demo_performance_metrics():
    """æ¼”ç¤ºæ€§èƒ½æŒ‡æ ‡"""
    print("\n" + "=" * 60)
    print("æ€§èƒ½æŒ‡æ ‡è¯´æ˜")
    print("=" * 60)

    metrics = {
        "Duration": "æ€»æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰",
        "Throughput": "ååé‡ï¼ˆæ ·æœ¬/ç§’æˆ–æ“ä½œ/ç§’ï¼‰",
        "Memory Allocated": "åˆ†é…çš„å†…å­˜ï¼ˆMBï¼‰",
        "Memory Reserved": "ä¿ç•™çš„å†…å­˜ï¼ˆMBï¼‰",
        "Latency": "å»¶è¿Ÿï¼ˆæ¯«ç§’/æ ·æœ¬ï¼‰",
    }

    print("\nå…³é”®æ€§èƒ½æŒ‡æ ‡:")
    for metric, desc in metrics.items():
        print(f"  â€¢ {metric:20s}: {desc}")

    print("\næ€§èƒ½ç›®æ ‡:")
    print("  â€¢ æ•°æ®åŠ è½½: > 1000 samples/s")
    print("  â€¢ æ¨¡å‹æ¨ç†: > 100 samples/s (CPU), > 1000 samples/s (GPU)")
    print("  â€¢ å†…å­˜ä½¿ç”¨: < 8GB (è®­ç»ƒ), < 2GB (æ¨ç†)")


def demo_regression_testing():
    """æ¼”ç¤ºå›å½’æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("æ€§èƒ½å›å½’æµ‹è¯•")
    print("=" * 60)

    print("\nä»€ä¹ˆæ˜¯æ€§èƒ½å›å½’?")
    print("  ä»£ç å˜æ›´å¯¼è‡´æ€§èƒ½ä¸‹é™è¶…è¿‡å¯æ¥å—çš„é˜ˆå€¼")

    print("\nå¦‚ä½•æ£€æµ‹å›å½’?")
    print("  1. å»ºç«‹æ€§èƒ½åŸºçº¿ï¼ˆbaselineï¼‰")
    print("  2. æ¯æ¬¡ä»£ç å˜æ›´åè¿è¡ŒåŸºå‡†æµ‹è¯•")
    print("  3. æ¯”è¾ƒå½“å‰ç»“æœä¸åŸºçº¿")
    print("  4. å¦‚æœæ€§èƒ½ä¸‹é™ > 5%ï¼Œæ ‡è®°ä¸ºå›å½’")

    print("\nç¤ºä¾‹:")
    print("  åŸºçº¿ååé‡: 1000 samples/s")
    print("  å½“å‰ååé‡: 900 samples/s")
    print("  å˜åŒ–: -10% âŒ å›å½’!")

    print("\n  åŸºçº¿ååé‡: 1000 samples/s")
    print("  å½“å‰ååé‡: 980 samples/s")
    print("  å˜åŒ–: -2% âœ“ æ­£å¸¸")


def demo_optimization_workflow():
    """æ¼”ç¤ºä¼˜åŒ–å·¥ä½œæµ"""
    print("\n" + "=" * 60)
    print("æ€§èƒ½ä¼˜åŒ–å·¥ä½œæµ")
    print("=" * 60)

    steps = [
        ("1. å»ºç«‹åŸºçº¿", "è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä¿å­˜ç»“æœ"),
        ("2. è¯†åˆ«ç“¶é¢ˆ", "åˆ†æå“ªä¸ªéƒ¨åˆ†æœ€æ…¢"),
        ("3. å®æ–½ä¼˜åŒ–", "ä¿®æ”¹ä»£ç æå‡æ€§èƒ½"),
        ("4. éªŒè¯æ”¹è¿›", "é‡æ–°è¿è¡ŒåŸºå‡†æµ‹è¯•"),
        ("5. æ¯”è¾ƒç»“æœ", "ç¡®è®¤æ€§èƒ½æå‡"),
        ("6. æ›´æ–°åŸºçº¿", "å¦‚æœæ»¡æ„ï¼Œæ›´æ–°åŸºçº¿"),
    ]

    print("\nä¼˜åŒ–æ­¥éª¤:")
    for step, desc in steps:
        print(f"  {step:20s} â†’ {desc}")

    print("\nç¤ºä¾‹åœºæ™¯:")
    print("  é—®é¢˜: æ•°æ®åŠ è½½å¤ªæ…¢ï¼ˆ100 samples/sï¼‰")
    print("  ä¼˜åŒ–: æ·»åŠ  LRU ç¼“å­˜")
    print("  ç»“æœ: æå‡åˆ° 300 samples/s (3x)")
    print("  å†³ç­–: âœ“ æ¥å—ä¼˜åŒ–ï¼Œæ›´æ–°åŸºçº¿")


def demo_best_practices():
    """æ¼”ç¤ºæœ€ä½³å®è·µ"""
    print("\n" + "=" * 60)
    print("åŸºå‡†æµ‹è¯•æœ€ä½³å®è·µ")
    print("=" * 60)

    print("\nâœ… æ¨èåšæ³•:")
    practices = [
        "é¢„çƒ­ï¼ˆwarmupï¼‰- é¿å…å†·å¯åŠ¨å½±å“",
        "å¤šæ¬¡è¿­ä»£ - å‡å°‘æµ‹é‡è¯¯å·®",
        "å›ºå®šéšæœºç§å­ - ç¡®ä¿å¯é‡å¤æ€§",
        "éš”ç¦»æµ‹è¯• - é¿å…ç›¸äº’å¹²æ‰°",
        "è®°å½•ç¯å¢ƒ - CPU/GPU å‹å·ã€é©±åŠ¨ç‰ˆæœ¬",
        "è‡ªåŠ¨åŒ– - é›†æˆåˆ° CI/CD",
    ]

    for practice in practices:
        print(f"  â€¢ {practice}")

    print("\nâŒ é¿å…çš„åšæ³•:")
    antipatterns = [
        "åœ¨ç”Ÿäº§ç¯å¢ƒæµ‹è¯•",
        "å¿½ç•¥é¢„çƒ­é˜¶æ®µ",
        "å•æ¬¡æµ‹é‡",
        "ä¸è®°å½•ç¯å¢ƒä¿¡æ¯",
        "æ‰‹åŠ¨è¿è¡Œæµ‹è¯•",
    ]

    for antipattern in antipatterns:
        print(f"  â€¢ {antipattern}")


def demo_ci_integration():
    """æ¼”ç¤º CI é›†æˆ"""
    print("\n" + "=" * 60)
    print("CI/CD é›†æˆ")
    print("=" * 60)

    print("\nGitHub Actions ç¤ºä¾‹:")
    yaml = '''
name: Performance Benchmarks

on: [push, pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -e .

      - name: Run benchmarks
        run: python scripts/run_benchmarks.py

      - name: Compare with baseline
        run: |
          python scripts/compare_benchmarks.py \\
            --baseline benchmarks/baseline.json \\
            --current benchmarks/current.json \\
            --tolerance 0.05

      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-results
          path: benchmarks/
'''
    print(yaml)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("MedFusion æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤º")
    print("=" * 60)

    try:
        # æ¼”ç¤º 1: ç®€å•åŸºå‡†æµ‹è¯•
        demo_simple_benchmark()

        # æ¼”ç¤º 2: åŸºå‡†æµ‹è¯•å¥—ä»¶
        demo_benchmark_suite()

        # æ¼”ç¤º 3: æ€§èƒ½æŒ‡æ ‡
        demo_performance_metrics()

        # æ¼”ç¤º 4: å›å½’æµ‹è¯•
        demo_regression_testing()

        # æ¼”ç¤º 5: ä¼˜åŒ–å·¥ä½œæµ
        demo_optimization_workflow()

        # æ¼”ç¤º 6: æœ€ä½³å®è·µ
        demo_best_practices()

        # æ¼”ç¤º 7: CI é›†æˆ
        demo_ci_integration()

        print("\n" + "=" * 60)
        print("æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)

        print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
        print("  1. å»ºç«‹æ€§èƒ½åŸºçº¿å¹¶å®šæœŸæ›´æ–°")
        print("  2. è‡ªåŠ¨åŒ–åŸºå‡†æµ‹è¯•ï¼Œé›†æˆåˆ° CI/CD")
        print("  3. ç›‘æ§æ€§èƒ½å›å½’ï¼ŒåŠæ—¶å‘ç°é—®é¢˜")
        print("  4. è®°å½•ä¼˜åŒ–å†å²ï¼Œè¿½è¸ªæ€§èƒ½æ”¹è¿›")

        print("\nğŸ“– ç›¸å…³èµ„æº:")
        print("  â€¢ med_core/utils/benchmark.py - åŸºå‡†æµ‹è¯•å·¥å…·")
        print("  â€¢ scripts/run_benchmarks.py - è¿è¡Œè„šæœ¬")
        print("  â€¢ benchmarks/ - åŸºå‡†æµ‹è¯•ç»“æœ")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
