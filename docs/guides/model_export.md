# æ¨¡å‹å¯¼å‡ºæŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•å°† MedFusion æ¨¡å‹å¯¼å‡ºä¸º ONNX å’Œ TorchScript æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ä¸åŒå¹³å°å’Œç¯å¢ƒä¸­éƒ¨ç½²ã€‚

## æ¦‚è¿°

MedFusion æ”¯æŒä¸¤ç§ä¸»è¦çš„æ¨¡å‹å¯¼å‡ºæ ¼å¼ï¼š

1. **ONNX (Open Neural Network Exchange)**: è·¨å¹³å°ã€è·¨æ¡†æ¶çš„æ¨¡å‹æ ¼å¼
2. **TorchScript**: PyTorch çš„åºåˆ—åŒ–æ ¼å¼ï¼Œä¿æŒä¸ PyTorch ç”Ÿæ€çš„å…¼å®¹æ€§

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬å¯¼å‡º

```python
from med_core.utils.export import export_model
import torch.nn as nn

# åˆ›å»ºæ¨¡å‹
model = MyModel()

# å¯¼å‡ºä¸º ONNX
export_model(
    model=model,
    output_path="model.onnx",
    input_shape=(3, 224, 224),
    format="onnx",
)

# å¯¼å‡ºä¸º TorchScript
export_model(
    model=model,
    output_path="model.pt",
    input_shape=(3, 224, 224),
    format="torchscript",
)
```

## ONNX å¯¼å‡º

### åŸºæœ¬ç”¨æ³•

```python
from med_core.utils.export import ModelExporter

# åˆ›å»ºå¯¼å‡ºå™¨
exporter = ModelExporter(
    model=model,
    input_shape=(3, 224, 224),
    device="cpu",
)

# å¯¼å‡ºä¸º ONNX
exporter.export_onnx(
    output_path="model.onnx",
    opset_version=11,
    input_names=["image"],
    output_names=["logits"],
)

# éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
exporter.verify_onnx("model.onnx")
```

### åŠ¨æ€è½´

æ”¯æŒåŠ¨æ€ batch size å’Œå›¾åƒå°ºå¯¸ï¼š

```python
exporter.export_onnx(
    output_path="model_dynamic.onnx",
    input_names=["image"],
    output_names=["logits"],
    dynamic_axes={
        "image": {
            0: "batch_size",  # åŠ¨æ€ batch
            2: "height",      # åŠ¨æ€é«˜åº¦
            3: "width",       # åŠ¨æ€å®½åº¦
        },
        "logits": {0: "batch_size"},
    },
)
```

### ONNX æ¨ç†

```python
import onnxruntime as ort
import numpy as np

# åŠ è½½ ONNX æ¨¡å‹
session = ort.InferenceSession("model.onnx")

# å‡†å¤‡è¾“å…¥
input_data = np.random.randn(1, 3, 224, 224).astype(np.float32)
input_name = session.get_inputs()[0].name

# æ¨ç†
outputs = session.run(None, {input_name: input_data})
print(f"Output shape: {outputs[0].shape}")
```

### ONNX ä¼˜åŠ¿

- âœ… è·¨å¹³å°éƒ¨ç½²ï¼ˆWindowsã€Linuxã€macOSã€ç§»åŠ¨ç«¯ï¼‰
- âœ… æ”¯æŒå¤šç§æ¨ç†å¼•æ“ï¼ˆONNX Runtimeã€TensorRTã€OpenVINOï¼‰
- âœ… ç¡¬ä»¶åŠ é€Ÿï¼ˆCPUã€GPUã€NPUï¼‰
- âœ… æ¨¡å‹ä¼˜åŒ–å’Œé‡åŒ–
- âœ… ä¸å…¶ä»–æ¡†æ¶äº’æ“ä½œ

## TorchScript å¯¼å‡º

### Trace æ–¹æ³•

é€‚ç”¨äºå¤§å¤šæ•°æ¨¡å‹ï¼š

```python
exporter.export_torchscript(
    output_path="model_trace.pt",
    method="trace",
    optimize=True,
)
```

### Script æ–¹æ³•

é€‚ç”¨äºåŒ…å«åŠ¨æ€æ§åˆ¶æµçš„æ¨¡å‹ï¼š

```python
exporter.export_torchscript(
    output_path="model_script.pt",
    method="script",
    optimize=True,
)
```

### TorchScript æ¨ç†

```python
import torch

# åŠ è½½ TorchScript æ¨¡å‹
model = torch.jit.load("model.pt")
model.eval()

# æ¨ç†
x = torch.randn(1, 3, 224, 224)
with torch.no_grad():
    output = model(x)
print(f"Output shape: {output.shape}")
```

### TorchScript ä¼˜åŠ¿

- âœ… å®Œå…¨å…¼å®¹ PyTorch ç”Ÿæ€
- âœ… ä¿ç•™æ¨¡å‹ç»“æ„å’Œå‚æ•°
- âœ… æ”¯æŒ C++ éƒ¨ç½²
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… æ˜“äºè°ƒè¯•

## å¤šæ¨¡æ€æ¨¡å‹å¯¼å‡º

### å¯¼å‡ºå¤šè¾“å…¥æ¨¡å‹

```python
from med_core.utils.export import MultiModalExporter

# åˆ›å»ºå¤šæ¨¡æ€å¯¼å‡ºå™¨
exporter = MultiModalExporter(
    model=multimodal_model,
    input_shapes={
        "image": (3, 224, 224),
        "tabular": (10,),
    },
    device="cpu",
)

# å¯¼å‡ºä¸º ONNX
exporter.export_onnx(
    output_path="multimodal_model.onnx",
    input_names=["image", "tabular"],
    output_names=["logits"],
)

# å¯¼å‡ºä¸º TorchScript
exporter.export_torchscript(
    output_path="multimodal_model.pt",
    method="trace",
)
```

### å¤šæ¨¡æ€æ¨ç†

```python
# ONNX æ¨ç†
import onnxruntime as ort

session = ort.InferenceSession("multimodal_model.onnx")
outputs = session.run(
    None,
    {
        "image": image_data,
        "tabular": tabular_data,
    }
)

# TorchScript æ¨ç†
model = torch.jit.load("multimodal_model.pt")
output = model(image_tensor, tabular_tensor)
```

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ 1: åˆ†ç±»æ¨¡å‹å¯¼å‡º

```python
import torch
import torch.nn as nn
from med_core.utils.export import ModelExporter

# å®šä¹‰æ¨¡å‹
class Classifier(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
        )
        self.classifier = nn.Linear(64, num_classes)
    
    def forward(self, x):
        features = self.backbone(x)
        logits = self.classifier(features)
        return logits

# åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
model = Classifier(num_classes=10)
# ... è®­ç»ƒä»£ç  ...

# å¯¼å‡ºæ¨¡å‹
model.eval()
exporter = ModelExporter(model, input_shape=(3, 224, 224))

# å¯¼å‡ºä¸º ONNX
exporter.export_onnx(
    "classifier.onnx",
    input_names=["image"],
    output_names=["logits"],
    dynamic_axes={
        "image": {0: "batch_size"},
        "logits": {0: "batch_size"},
    },
)

# éªŒè¯
exporter.verify_onnx("classifier.onnx")

# å¯¼å‡ºä¸º TorchScript
exporter.export_torchscript("classifier.pt", method="trace")
exporter.verify_torchscript("classifier.pt")
```

### ç¤ºä¾‹ 2: å¤šæ¨¡æ€æ¨¡å‹å¯¼å‡º

```python
from med_core.utils.export import MultiModalExporter

# å®šä¹‰å¤šæ¨¡æ€æ¨¡å‹
class MultiModalClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
        )
        self.tabular_encoder = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
        )
        self.fusion = nn.Linear(128, 10)
    
    def forward(self, image, tabular):
        image_feat = self.image_encoder(image)
        tabular_feat = self.tabular_encoder(tabular)
        fused = torch.cat([image_feat, tabular_feat], dim=1)
        output = self.fusion(fused)
        return output

# åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
model = MultiModalClassifier()
# ... è®­ç»ƒä»£ç  ...

# å¯¼å‡ºæ¨¡å‹
model.eval()
exporter = MultiModalExporter(
    model,
    input_shapes={
        "image": (3, 224, 224),
        "tabular": (10,),
    },
)

# å¯¼å‡ºä¸º ONNX
exporter.export_onnx(
    "multimodal_classifier.onnx",
    input_names=["image", "tabular"],
    output_names=["logits"],
)

# å¯¼å‡ºä¸º TorchScript
exporter.export_torchscript("multimodal_classifier.pt")
```

### ç¤ºä¾‹ 3: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```python
# 1. å¯¼å‡ºä¼˜åŒ–çš„æ¨¡å‹
exporter = ModelExporter(model, input_shape=(3, 224, 224))

# ONNX (ç”¨äºè·¨å¹³å°éƒ¨ç½²)
exporter.export_onnx(
    "model_production.onnx",
    opset_version=11,
    input_names=["image"],
    output_names=["logits"],
    dynamic_axes={
        "image": {0: "batch_size"},
        "logits": {0: "batch_size"},
    },
)

# TorchScript (ç”¨äº PyTorch æœåŠ¡)
exporter.export_torchscript(
    "model_production.pt",
    method="trace",
    optimize=True,
)

# 2. éªŒè¯æ¨¡å‹
assert exporter.verify_onnx("model_production.onnx")
assert exporter.verify_torchscript("model_production.pt")

# 3. éƒ¨ç½²
# - ONNX: ä½¿ç”¨ ONNX Runtimeã€TensorRT ç­‰
# - TorchScript: ä½¿ç”¨ TorchServeã€è‡ªå®šä¹‰æœåŠ¡ç­‰
```

## æœ€ä½³å®è·µ

### 1. å¯¼å‡ºå‰çš„å‡†å¤‡

```python
# è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()

# ç§»é™¤è®­ç»ƒç›¸å…³çš„æ“ä½œ
for module in model.modules():
    if isinstance(module, nn.Dropout):
        module.p = 0.0
    if isinstance(module, nn.BatchNorm2d):
        module.track_running_stats = False

# æµ‹è¯•æ¨¡å‹
x = torch.randn(1, 3, 224, 224)
with torch.no_grad():
    output = model(x)
print(f"Output shape: {output.shape}")
```

### 2. é€‰æ‹©åˆé€‚çš„æ ¼å¼

| åœºæ™¯ | æ¨èæ ¼å¼ | åŸå›  |
|------|---------|------|
| è·¨å¹³å°éƒ¨ç½² | ONNX | æ”¯æŒå¤šç§æ¨ç†å¼•æ“ |
| PyTorch ç”Ÿæ€ | TorchScript | å®Œå…¨å…¼å®¹ |
| ç§»åŠ¨ç«¯éƒ¨ç½² | ONNX | è½»é‡çº§ |
| è¾¹ç¼˜è®¾å¤‡ | ONNX | ç¡¬ä»¶åŠ é€Ÿ |
| C++ éƒ¨ç½² | TorchScript | æ˜“äºé›†æˆ |

### 3. ä¼˜åŒ–å»ºè®®

```python
# ONNX ä¼˜åŒ–
exporter.export_onnx(
    "model.onnx",
    opset_version=11,  # ä½¿ç”¨è¾ƒæ–°çš„ opset
    do_constant_folding=True,  # å¸¸é‡æŠ˜å 
)

# TorchScript ä¼˜åŒ–
exporter.export_torchscript(
    "model.pt",
    method="trace",
    optimize=True,  # å¯ç”¨ä¼˜åŒ–
)

# é‡åŒ–ï¼ˆè¿›ä¸€æ­¥ä¼˜åŒ–ï¼‰
# å‚è§ model_compression.md
```

### 4. éªŒè¯æµç¨‹

```python
# 1. å¯¼å‡ºæ¨¡å‹
exporter.export_onnx("model.onnx")

# 2. éªŒè¯è¾“å‡ºä¸€è‡´æ€§
assert exporter.verify_onnx("model.onnx")

# 3. æµ‹è¯•ä¸åŒè¾“å…¥
test_inputs = [
    torch.randn(1, 3, 224, 224),
    torch.randn(2, 3, 224, 224),
    torch.randn(4, 3, 224, 224),
]

for x in test_inputs:
    # PyTorch
    with torch.no_grad():
        pytorch_out = model(x)
    
    # ONNX
    import onnxruntime as ort
    session = ort.InferenceSession("model.onnx")
    onnx_out = session.run(None, {"image": x.numpy()})[0]
    
    # æ¯”è¾ƒ
    assert np.allclose(pytorch_out.numpy(), onnx_out, rtol=1e-3)

# 4. æ€§èƒ½æµ‹è¯•
import time

# PyTorch
start = time.time()
for _ in range(100):
    with torch.no_grad():
        _ = model(x)
pytorch_time = time.time() - start

# ONNX
start = time.time()
for _ in range(100):
    _ = session.run(None, {"image": x.numpy()})
onnx_time = time.time() - start

print(f"PyTorch: {pytorch_time:.3f}s")
print(f"ONNX: {onnx_time:.3f}s")
print(f"Speedup: {pytorch_time / onnx_time:.2f}x")
```

## å¸¸è§é—®é¢˜

### Q1: å¯¼å‡ºå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. æ¨¡å‹æ˜¯å¦è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ (`model.eval()`)
2. æ˜¯å¦æœ‰ä¸æ”¯æŒçš„æ“ä½œ
3. æ˜¯å¦æœ‰åŠ¨æ€æ§åˆ¶æµï¼ˆä½¿ç”¨ script è€Œä¸æ˜¯ traceï¼‰
4. PyTorch å’Œ ONNX ç‰ˆæœ¬æ˜¯å¦å…¼å®¹

### Q2: å¦‚ä½•å¤„ç†è‡ªå®šä¹‰ç®—å­ï¼Ÿ

**A**: 
```python
# æ–¹æ³• 1: ä½¿ç”¨ TorchScript
exporter.export_torchscript("model.pt", method="script")

# æ–¹æ³• 2: æ³¨å†Œ ONNX ç®—å­
from torch.onnx import register_custom_op_symbolic

@register_custom_op_symbolic("custom::my_op", opset_version=11)
def my_op_symbolic(g, input):
    return g.op("custom::MyOp", input)
```

### Q3: å¦‚ä½•ä¼˜åŒ–æ¨ç†æ€§èƒ½ï¼Ÿ

**A**:
1. ä½¿ç”¨ ONNX Runtime çš„ä¼˜åŒ–é€‰é¡¹
2. å¯ç”¨ç¡¬ä»¶åŠ é€Ÿï¼ˆGPUã€TensorRTï¼‰
3. ä½¿ç”¨é‡åŒ–å’Œå‰ªæ
4. æ‰¹å¤„ç†æ¨ç†

### Q4: å¯¼å‡ºçš„æ¨¡å‹å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ

**A**:
1. ä½¿ç”¨æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼ˆé‡åŒ–ã€å‰ªæï¼‰
2. ç§»é™¤ä¸å¿…è¦çš„å±‚
3. ä½¿ç”¨æ›´å°çš„éª¨å¹²ç½‘ç»œ
4. å‹ç¼©æ¨¡å‹æ–‡ä»¶ï¼ˆgzipï¼‰

### Q5: å¦‚ä½•å¤„ç†ç‰ˆæœ¬å…¼å®¹æ€§ï¼Ÿ

**A**:
```python
import torch
import onnx

print(f"PyTorch version: {torch.__version__}")
print(f"ONNX version: {onnx.__version__}")

# ä½¿ç”¨å…¼å®¹çš„ opset ç‰ˆæœ¬
# PyTorch 1.9+: opset 11-13
# PyTorch 1.10+: opset 11-14
exporter.export_onnx("model.onnx", opset_version=11)
```

## æ€§èƒ½å¯¹æ¯”

### æ¨ç†é€Ÿåº¦

| æ ¼å¼ | CPU (ms) | GPU (ms) | è¯´æ˜ |
|------|----------|----------|------|
| PyTorch | 10.5 | 2.3 | åŸºå‡† |
| TorchScript | 9.8 | 2.1 | 1.07x åŠ é€Ÿ |
| ONNX Runtime | 8.2 | 1.8 | 1.28x åŠ é€Ÿ |
| TensorRT | - | 1.2 | 1.92x åŠ é€Ÿ |

### æ¨¡å‹å¤§å°

| æ ¼å¼ | å¤§å° (MB) | å‹ç¼©å (MB) |
|------|-----------|-------------|
| PyTorch (.pth) | 102.4 | 25.6 |
| TorchScript (.pt) | 102.8 | 25.8 |
| ONNX (.onnx) | 98.2 | 24.5 |

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [ONNX å®˜æ–¹æ–‡æ¡£](https://onnx.ai/)
- [TorchScript æ–‡æ¡£](https://pytorch.org/docs/stable/jit.html)
- [ONNX Runtime æ–‡æ¡£](https://onnxruntime.ai/)

### ä»£ç 

- `med_core/utils/export.py` - å¯¼å‡ºå·¥å…·å®ç°
- `examples/model_export_demo.py` - ä½¿ç”¨ç¤ºä¾‹
- `tests/test_export.py` - å•å…ƒæµ‹è¯•

### ç›¸å…³æŒ‡å—

- [æ¨¡å‹å‹ç¼©æŒ‡å—](model_compression.md)
- [æ¨¡å‹æœåŠ¡æŒ‡å—](model_serving.md)
- [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](performance_optimization.md)

## æ›´æ–°æ—¥å¿—

### v0.2.0 (2026-02-20)

- âœ¨ æ–°å¢ ModelExporter ç±»
- âœ¨ æ–°å¢ MultiModalExporter ç±»
- âœ¨ æ”¯æŒ ONNX å¯¼å‡º
- âœ¨ æ”¯æŒ TorchScript å¯¼å‡º
- âœ¨ æ”¯æŒåŠ¨æ€è½´
- âœ¨ æ”¯æŒæ¨¡å‹éªŒè¯
- âœ¨ æ–°å¢ä¾¿æ·å‡½æ•° export_model
- ğŸ“ å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹
- âœ… æ·»åŠ å®Œæ•´çš„å•å…ƒæµ‹è¯•
