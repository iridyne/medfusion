# æ¢¯åº¦æ£€æŸ¥ç‚¹ä½¿ç”¨æŒ‡å—

## ğŸ“– æ¦‚è¿°

æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰æ˜¯ä¸€ç§å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—ä¸­é—´æ¿€æ´»å€¼æ¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚MedFusion æ¡†æ¶ä¸ºæ‰€æœ‰ backbone æ¨¡å‹æä¾›äº†æ¢¯åº¦æ£€æŸ¥ç‚¹æ”¯æŒã€‚

### ä¼˜åŠ¿
- **å†…å­˜èŠ‚çœ**: 25-50% (å–å†³äºæ¨¡å‹å’Œé…ç½®)
- **æ›´å¤§çš„ Batch Size**: å¯ä»¥è®­ç»ƒæ›´å¤§çš„æ‰¹æ¬¡
- **æ›´å¤§çš„æ¨¡å‹**: å¯ä»¥ä½¿ç”¨æ›´æ·±çš„ç½‘ç»œ

### æƒè¡¡
- **è®­ç»ƒæ—¶é—´å¢åŠ **: 10-30% (ç”±äºé‡æ–°è®¡ç®—)
- **æ¨ç†æ— å½±å“**: ä»…åœ¨è®­ç»ƒæ—¶å¯ç”¨

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from med_core.backbones import create_backbone

# åˆ›å»º backbone
backbone = create_backbone(
    "resnet50",
    pretrained=True,
    feature_dim=128
)

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone.enable_gradient_checkpointing()

# æ£€æŸ¥æ˜¯å¦å¯ç”¨
assert backbone.is_gradient_checkpointing_enabled()

# æ­£å¸¸è®­ç»ƒ
for batch in dataloader:
    outputs = backbone(batch)
    loss = criterion(outputs, targets)
    loss.backward()
    optimizer.step()
```

### é…ç½®æ®µæ•°

```python
# é»˜è®¤ä½¿ç”¨ 4 ä¸ªæ®µ
backbone.enable_gradient_checkpointing()

# è‡ªå®šä¹‰æ®µæ•°ï¼ˆæ›´å¤šæ®µ = æ›´å°‘å†…å­˜ï¼Œä½†æ›´æ…¢ï¼‰
backbone.enable_gradient_checkpointing(segments=8)

# å¯¹äº Transformer æ¨¡å‹ï¼Œæ®µæ•°é€šå¸¸ç­‰äºå±‚æ•°
vit_backbone = create_backbone("vit_b_16")
vit_backbone.enable_gradient_checkpointing()  # è‡ªåŠ¨ä½¿ç”¨ 12 ä¸ªæ®µï¼ˆ12 å±‚ï¼‰
```

### ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

```python
# ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone.disable_gradient_checkpointing()

# æ£€æŸ¥çŠ¶æ€
assert not backbone.is_gradient_checkpointing_enabled()
```

---

## ğŸ“Š æ”¯æŒçš„æ¨¡å‹

### æ‰€æœ‰ Backbone éƒ½æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹

| æ¨¡å‹ç³»åˆ— | å˜ä½“ | å®ç°æ¨¡å¼ | é¢„è®¡å†…å­˜èŠ‚çœ |
|---------|------|---------|-------------|
| ResNet | 18, 34, 50, 101, 152 | æ¨¡å¼ 1 (é¡ºåºå±‚) | 30-40% |
| MobileNet | V2, V3 Small/Large | æ¨¡å¼ 1 (é¡ºåºå±‚) | 25-35% |
| EfficientNet | B0, B1, B2 | æ¨¡å¼ 1 (é¡ºåºå±‚) | 30-40% |
| EfficientNetV2 | S, M, L | æ¨¡å¼ 1 (é¡ºåºå±‚) | 30-40% |
| RegNet | Y-series (400MF-32GF) | æ¨¡å¼ 1 (é¡ºåºå±‚) | 30-40% |
| ViT | B16, B32, L16, L32 | æ¨¡å¼ 2 (Transformer) | 40-50% |
| Swin | Tiny, Small, Base | æ¨¡å¼ 2 (Transformer) | 40-50% |
| ConvNeXt | Tiny, Small, Base, Large | æ¨¡å¼ 3 (æ··åˆæ¶æ„) | 35-45% |
| MaxViT | Tiny | æ¨¡å¼ 2 (Transformer) | 40-50% |

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: å†…å­˜ä¸è¶³

**é—®é¢˜**: è®­ç»ƒæ—¶é‡åˆ° CUDA Out of Memory é”™è¯¯

```python
# ä¹‹å‰: å†…å­˜ä¸è¶³
backbone = create_backbone("resnet101", pretrained=True)
# RuntimeError: CUDA out of memory

# è§£å†³æ–¹æ¡ˆ: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone = create_backbone("resnet101", pretrained=True)
backbone.enable_gradient_checkpointing()
# è®­ç»ƒæˆåŠŸï¼
```

### åœºæ™¯ 2: å¢å¤§ Batch Size

**ç›®æ ‡**: ä½¿ç”¨æ›´å¤§çš„ batch size æé«˜è®­ç»ƒç¨³å®šæ€§

```python
# ä¹‹å‰: batch_size = 16
dataloader = DataLoader(dataset, batch_size=16)

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹å: batch_size = 32
backbone.enable_gradient_checkpointing()
dataloader = DataLoader(dataset, batch_size=32)
```

### åœºæ™¯ 3: ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹

**ç›®æ ‡**: ä½¿ç”¨æ›´æ·±çš„ç½‘ç»œæé«˜æ€§èƒ½

```python
# ä¹‹å‰: åªèƒ½ä½¿ç”¨ resnet50
backbone = create_backbone("resnet50")

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹å: å¯ä»¥ä½¿ç”¨ resnet152
backbone = create_backbone("resnet152")
backbone.enable_gradient_checkpointing()
```

### åœºæ™¯ 4: å¤šè§†å›¾è®­ç»ƒ

**ç›®æ ‡**: è®­ç»ƒå¤šè§†å›¾æ¨¡å‹æ—¶èŠ‚çœå†…å­˜

```python
from med_core.models import MultiViewClassifier

model = MultiViewClassifier(
    backbone_name="resnet50",
    num_classes=2,
    num_views=4,
    aggregation="attention"
)

# ä¸º backbone å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.backbone.enable_gradient_checkpointing()

# è®­ç»ƒå¤šè§†å›¾æ•°æ®
for views, labels in dataloader:
    # views: (B, num_views, C, H, W)
    outputs = model(views)
    loss = criterion(outputs, labels)
    loss.backward()
```

---

## âš™ï¸ é«˜çº§é…ç½®

### ä¸æ··åˆç²¾åº¦è®­ç»ƒç»“åˆ

```python
from torch.cuda.amp import autocast, GradScaler

backbone = create_backbone("resnet50")
backbone.enable_gradient_checkpointing()

scaler = GradScaler()

for batch in dataloader:
    optimizer.zero_grad()
    
    # æ··åˆç²¾åº¦ + æ¢¯åº¦æ£€æŸ¥ç‚¹
    with autocast():
        outputs = backbone(batch)
        loss = criterion(outputs, targets)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

### åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨

```yaml
# configs/my_config.yaml
model:
  backbone:
    name: resnet50
    pretrained: true
    feature_dim: 128
    
training:
  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
  gradient_checkpointing:
    enabled: true
    segments: 4  # å¯é€‰ï¼Œé»˜è®¤ä¸º 4
  
  # æ··åˆç²¾åº¦è®­ç»ƒ
  use_amp: true
  
  # å¯ä»¥ä½¿ç”¨æ›´å¤§çš„ batch size
  batch_size: 32
```

### åŠ¨æ€å¯ç”¨/ç¦ç”¨

```python
# è®­ç»ƒæ—¶å¯ç”¨
model.train()
backbone.enable_gradient_checkpointing()

# éªŒè¯æ—¶ç¦ç”¨ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
model.eval()
backbone.disable_gradient_checkpointing()

# æˆ–è€…ä¿æŒå¯ç”¨ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹åœ¨ eval æ¨¡å¼ä¸‹è‡ªåŠ¨ç¦ç”¨ï¼‰
model.eval()
# æ¢¯åº¦æ£€æŸ¥ç‚¹ä¸ä¼šå½±å“æ¨ç†
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### å†…å­˜ä½¿ç”¨å¯¹æ¯”

| æ¨¡å‹ | Batch Size | æ— æ£€æŸ¥ç‚¹ | æœ‰æ£€æŸ¥ç‚¹ | èŠ‚çœ |
|------|-----------|---------|---------|------|
| ResNet50 | 32 | 8.2 GB | 5.4 GB | 34% |
| ResNet101 | 32 | 12.1 GB | 7.8 GB | 36% |
| ViT-B/16 | 32 | 10.5 GB | 5.8 GB | 45% |
| ConvNeXt-Base | 32 | 9.8 GB | 6.2 GB | 37% |
| EfficientNet-B2 | 32 | 7.5 GB | 5.1 GB | 32% |

### è®­ç»ƒæ—¶é—´å¯¹æ¯”

| æ¨¡å‹ | æ— æ£€æŸ¥ç‚¹ | æœ‰æ£€æŸ¥ç‚¹ (4æ®µ) | æœ‰æ£€æŸ¥ç‚¹ (8æ®µ) | å¢åŠ  |
|------|---------|--------------|--------------|------|
| ResNet50 | 100s | 115s | 128s | 15-28% |
| ViT-B/16 | 120s | 138s | 152s | 15-27% |
| ConvNeXt-Base | 110s | 125s | 140s | 14-27% |

**å»ºè®®**: ä½¿ç”¨ 4 ä¸ªæ®µå¯ä»¥åœ¨å†…å­˜èŠ‚çœå’Œè®­ç»ƒé€Ÿåº¦ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: ä»ç„¶å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ æ®µæ•°
```python
backbone.enable_gradient_checkpointing(segments=8)
```

2. ç»“åˆå…¶ä»–ä¼˜åŒ–æŠ€æœ¯
```python
# å¯ç”¨æ··åˆç²¾åº¦
from torch.cuda.amp import autocast

# å‡å° batch size
dataloader = DataLoader(dataset, batch_size=16)

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 2
```

3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
```python
# ä» resnet101 é™çº§åˆ° resnet50
backbone = create_backbone("resnet50")
```

### é—®é¢˜ 2: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°‘æ®µæ•°
```python
backbone.enable_gradient_checkpointing(segments=2)
```

2. ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨
```python
# åªåœ¨å¤§æ¨¡å‹ä¸Šä½¿ç”¨
if model_size == "large":
    backbone.enable_gradient_checkpointing()
```

3. ä½¿ç”¨æ›´å¿«çš„ç¡¬ä»¶
- å‡çº§åˆ°æ›´æ–°çš„ GPU (A100, H100)
- ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ

### é—®é¢˜ 3: ä¸æŸäº›æ“ä½œä¸å…¼å®¹

**ç—‡çŠ¶**: æŸäº›è‡ªå®šä¹‰å±‚æˆ–æ“ä½œå¯¼è‡´é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone.disable_gradient_checkpointing()

# æˆ–è€…åªåœ¨ç‰¹å®šå±‚å¯ç”¨
# (éœ€è¦è‡ªå®šä¹‰å®ç°)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

âœ… **æ¨èä½¿ç”¨**:
- è®­ç»ƒå¤§å‹æ¨¡å‹ (ResNet101+, ViT-Large)
- ä½¿ç”¨å¤§ batch size (>32)
- GPU å†…å­˜æœ‰é™ (8GB, 12GB)
- å¤šè§†å›¾/å¤šæ¨¡æ€è®­ç»ƒ
- é«˜åˆ†è¾¨ç‡å›¾åƒ (>512x512)

âŒ **ä¸æ¨èä½¿ç”¨**:
- å°å‹æ¨¡å‹ (ResNet18, MobileNet)
- å° batch size (<16)
- å……è¶³çš„ GPU å†…å­˜
- å¯¹è®­ç»ƒé€Ÿåº¦è¦æ±‚æé«˜
- æ¨ç†é˜¶æ®µï¼ˆè‡ªåŠ¨ç¦ç”¨ï¼‰

### 2. æ®µæ•°é€‰æ‹©

| æ¨¡å‹ç±»å‹ | æ¨èæ®µæ•° | è¯´æ˜ |
|---------|---------|------|
| CNN (ResNet, EfficientNet) | 4 | å¹³è¡¡å†…å­˜å’Œé€Ÿåº¦ |
| Transformer (ViT, Swin) | å±‚æ•° | æ¯å±‚ä¸€ä¸ªæ£€æŸ¥ç‚¹ |
| æ··åˆæ¶æ„ (ConvNeXt) | 4 | æŒ‰ stage åˆ†æ®µ |
| å†…å­˜æåº¦å—é™ | 8+ | æœ€å¤§åŒ–å†…å­˜èŠ‚çœ |

### 3. ä¸å…¶ä»–ä¼˜åŒ–ç»“åˆ

```python
# å®Œæ•´çš„å†…å­˜ä¼˜åŒ–é…ç½®
backbone = create_backbone("resnet101")

# 1. æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone.enable_gradient_checkpointing(segments=4)

# 2. æ··åˆç²¾åº¦
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

# 3. æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4

# 4. ä¼˜åŒ–å™¨çŠ¶æ€
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-4,
    weight_decay=0.01
)

# è®­ç»ƒå¾ªç¯
for i, (inputs, targets) in enumerate(dataloader):
    with autocast():
        outputs = backbone(inputs)
        loss = criterion(outputs, targets) / accumulation_steps
    
    scaler.scale(loss).backward()
    
    if (i + 1) % accumulation_steps == 0:
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()
```

### 4. ç›‘æ§å†…å­˜ä½¿ç”¨

```python
import torch

def print_memory_stats():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved")

# è®­ç»ƒå‰
print_memory_stats()

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
backbone.enable_gradient_checkpointing()

# è®­ç»ƒå
print_memory_stats()
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
- [Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/abs/1604.06174)
- [Gradient Checkpointing for PyTorch](https://pytorch.org/docs/stable/checkpoint.html)

### ç›¸å…³æ–‡æ¡£
- [MedFusion æ¶æ„è®¾è®¡](../architecture/gradient_checkpointing_design.md)
- [ä¼˜åŒ–è·¯çº¿å›¾](../architecture/optimization_roadmap.md)
- [æ€§èƒ½åŸºå‡†æµ‹è¯•](performance_benchmarking.md)

### ä»£ç ç¤ºä¾‹
- [åŸºç¡€ç¤ºä¾‹](../../examples/gradient_checkpointing_demo.py)
- [å¤šè§†å›¾ç¤ºä¾‹](../../examples/multiview_training_demo.py)
- [åˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹](../../examples/distributed_training_demo.py)

---

## ğŸ¤ è´¡çŒ®

å¦‚æœä½ å‘ç°ä»»ä½•é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿ï¼š
1. æäº¤ Issue
2. åˆ›å»º Pull Request
3. å‚ä¸è®¨è®º

---

**æœ€åæ›´æ–°**: 2026-02-20  
**ä½œè€…**: MedFusion Team  
**ç‰ˆæœ¬**: 1.0
