# FAQ å’Œæ•…éšœæ’æŸ¥æŒ‡å—

æœ¬æŒ‡å—æä¾› MedFusion æ¡†æ¶å¸¸è§é—®é¢˜çš„è§£ç­”å’Œæ•…éšœæ’æŸ¥æ–¹æ³•ã€‚

## ç›®å½•

- [å¸¸è§é—®é¢˜ (FAQ)](#å¸¸è§é—®é¢˜-faq)
- [å®‰è£…é—®é¢˜](#å®‰è£…é—®é¢˜)
- [é…ç½®é—®é¢˜](#é…ç½®é—®é¢˜)
- [è®­ç»ƒé—®é¢˜](#è®­ç»ƒé—®é¢˜)
- [æ•°æ®åŠ è½½é—®é¢˜](#æ•°æ®åŠ è½½é—®é¢˜)
- [GPU å’Œå†…å­˜é—®é¢˜](#gpu-å’Œå†…å­˜é—®é¢˜)
- [æ¨¡å‹é—®é¢˜](#æ¨¡å‹é—®é¢˜)
- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
- [Docker é—®é¢˜](#docker-é—®é¢˜)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)

---

## å¸¸è§é—®é¢˜ (FAQ)

### Q1: MedFusion æ”¯æŒå“ªäº› Python ç‰ˆæœ¬ï¼Ÿ

**A**: MedFusion æ”¯æŒ Python 3.10, 3.11, å’Œ 3.12ã€‚

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# æ¨èä½¿ç”¨ Python 3.11
python3.11 -m venv .venv
```

### Q2: å¦‚ä½•å®‰è£… MedFusionï¼Ÿ

**A**: ä½¿ç”¨ uv æˆ– pip å®‰è£…ï¼š

```bash
# ä½¿ç”¨ uv (æ¨è)
uv pip install -e .

# ä½¿ç”¨ pip
pip install -e .

# å¼€å‘æ¨¡å¼ï¼ˆåŒ…å«å¼€å‘ä¾èµ–ï¼‰
uv pip install -e ".[dev]"
```

### Q3: éœ€è¦ GPU å—ï¼Ÿ

**A**: ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¼ºçƒˆæ¨èã€‚

- **è®­ç»ƒ**: æ¨èä½¿ç”¨ GPUï¼ˆCUDA 11.0+ï¼‰
- **æ¨ç†**: CPU ä¹Ÿå¯ä»¥ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢
- **å¼€å‘/æµ‹è¯•**: CPU è¶³å¤Ÿ

```bash
# æ£€æŸ¥ GPU å¯ç”¨æ€§
python -c "import torch; print(torch.cuda.is_available())"
```

### Q4: å¦‚ä½•æŸ¥çœ‹æ¡†æ¶ç‰ˆæœ¬ï¼Ÿ

**A**: 

```python
import med_core
print(med_core.__version__)
```

æˆ–ä½¿ç”¨ CLIï¼š

```bash
python -m med_core.cli --version
```

### Q5: æ”¯æŒå“ªäº›åŒ»å­¦å½±åƒæ¨¡æ€ï¼Ÿ

**A**: MedFusion æ”¯æŒå¤šç§æ¨¡æ€ï¼š

- CT (Computed Tomography)
- MRI (Magnetic Resonance Imaging)
- X-Ray
- PET (Positron Emission Tomography)
- ç—…ç†å›¾åƒ
- å¤šæ¨¡æ€èåˆ

### Q6: å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ

**A**: 

1. Fork ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. è¿è¡Œæµ‹è¯•å’Œæ£€æŸ¥
5. åˆ›å»º Pull Request

è¯¦è§ [CONTRIBUTING.md](../CONTRIBUTING.md)

### Q7: åœ¨å“ªé‡Œè·å–å¸®åŠ©ï¼Ÿ

**A**: 

- ğŸ“– æŸ¥çœ‹æ–‡æ¡£: `docs/`
- ğŸ› æŠ¥å‘Šé—®é¢˜: GitHub Issues
- ğŸ’¬ è®¨è®º: GitHub Discussions
- ğŸ“§ è”ç³»: your-email@example.com

---

## å®‰è£…é—®é¢˜

### é—®é¢˜ 1: å®‰è£…ä¾èµ–å¤±è´¥

**ç—‡çŠ¶**:
```
ERROR: Could not find a version that satisfies the requirement torch>=2.0.0
```

**åŸå› **: PyTorch ç‰ˆæœ¬ä¸å…¼å®¹æˆ–ç½‘ç»œé—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: ä½¿ç”¨æ¸…åé•œåƒ
pip install torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple

# æ–¹æ¡ˆ 2: ç›´æ¥ä» PyTorch å®˜ç½‘å®‰è£…
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# æ–¹æ¡ˆ 3: ä½¿ç”¨ uv (æ›´å¿«)
uv pip install torch torchvision
```

### é—®é¢˜ 2: CUDA ç‰ˆæœ¬ä¸åŒ¹é…

**ç—‡çŠ¶**:
```
RuntimeError: CUDA error: no kernel image is available for execution on the device
```

**åŸå› **: PyTorch CUDA ç‰ˆæœ¬ä¸ç³»ç»Ÿ CUDA ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥ç³»ç»Ÿ CUDA ç‰ˆæœ¬
nvidia-smi

# 2. å®‰è£…åŒ¹é…çš„ PyTorch
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CPU only
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### é—®é¢˜ 3: æƒé™é”™è¯¯

**ç—‡çŠ¶**:
```
PermissionError: [Errno 13] Permission denied
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# ä½¿ç”¨ç”¨æˆ·å®‰è£…
pip install --user -e .

# æˆ–ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate
pip install -e .
```

---

## é…ç½®é—®é¢˜

### é—®é¢˜ 1: é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥

**ç—‡çŠ¶**:
```
[E001] model.backbone: Invalid backbone 'resnet999'
```

**åŸå› **: é…ç½®å€¼æ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æŸ¥çœ‹å¯ç”¨é€‰é¡¹
python -c "from med_core.backbones import AVAILABLE_BACKBONES; print(AVAILABLE_BACKBONES)"

# 2. ä½¿ç”¨æœ‰æ•ˆçš„é…ç½®
# ç¼–è¾‘ configs/your_config.yaml
model:
  backbone: resnet50  # ä½¿ç”¨æœ‰æ•ˆçš„ backbone
```

### é—®é¢˜ 2: é…ç½®æ–‡ä»¶æ‰¾ä¸åˆ°

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'configs/my_config.yaml'
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# ä½¿ç”¨ç»å¯¹è·¯å¾„
python -m med_core.cli train --config /absolute/path/to/config.yaml

# æˆ–ä»æ­£ç¡®çš„ç›®å½•è¿è¡Œ
cd /path/to/medfusion
python -m med_core.cli train --config configs/my_config.yaml
```

### é—®é¢˜ 3: æ³¨æ„åŠ›ç›‘ç£é…ç½®é”™è¯¯

**ç—‡çŠ¶**:
```
[E028] Attention supervision requires CBAM attention mechanism
```

**åŸå› **: æ³¨æ„åŠ›ç›‘ç£éœ€è¦ CBAM

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# æ–¹æ¡ˆ 1: å¯ç”¨ CBAM
model:
  vision:
    attention_type: cbam

training:
  use_attention_supervision: true

# æ–¹æ¡ˆ 2: ç¦ç”¨æ³¨æ„åŠ›ç›‘ç£
training:
  use_attention_supervision: false
```

---

## è®­ç»ƒé—®é¢˜

### é—®é¢˜ 1: è®­ç»ƒç«‹å³å´©æºƒ

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
```

**åŸå› **: GPU å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. å‡å° batch size
training:
  batch_size: 8  # ä» 32 å‡å°

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
training:
  batch_size: 8
  gradient_accumulation_steps: 4  # ç­‰æ•ˆäº batch_size=32

# 3. ä½¿ç”¨æ··åˆç²¾åº¦
training:
  use_amp: true

# 4. å‡å°å›¾åƒå°ºå¯¸
data:
  image_size: 224  # ä» 512 å‡å°
```

### é—®é¢˜ 2: Loss å˜æˆ NaN

**ç—‡çŠ¶**:
```
Epoch 1, Step 100: loss=nan
```

**åŸå› **: å­¦ä¹ ç‡è¿‡å¤§ã€æ¢¯åº¦çˆ†ç‚¸ã€æ•°æ®é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. é™ä½å­¦ä¹ ç‡
training:
  optimizer:
    lr: 0.0001  # ä» 0.001 é™ä½

# 2. ä½¿ç”¨æ¢¯åº¦è£å‰ª
training:
  max_grad_norm: 1.0

# 3. æ£€æŸ¥æ•°æ®
# ç¡®ä¿æ•°æ®å½’ä¸€åŒ–æ­£ç¡®
data:
  normalize: true
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# 4. ä½¿ç”¨æ›´ç¨³å®šçš„ä¼˜åŒ–å™¨
training:
  optimizer:
    type: adamw
    weight_decay: 0.01
```

### é—®é¢˜ 3: è®­ç»ƒé€Ÿåº¦æ…¢

**ç—‡çŠ¶**: GPU åˆ©ç”¨ç‡ä½ï¼Œè®­ç»ƒç¼“æ…¢

**åŸå› **: æ•°æ®åŠ è½½ç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. å¢åŠ  data workers
data:
  num_workers: 8  # æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´
  pin_memory: true
  persistent_workers: true

# 2. ä½¿ç”¨æ›´å¿«çš„æ•°æ®æ ¼å¼
# å°†æ•°æ®è½¬æ¢ä¸º LMDB æˆ– TFRecord

# 3. é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
# å¦‚æœæ•°æ®é›†è¾ƒå°

# 4. ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®
```

### é—®é¢˜ 4: æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥

**ç—‡çŠ¶**:
```
OSError: [Errno 28] No space left on device
```

**åŸå› **: ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. åªä¿å­˜æœ€ä½³æ¨¡å‹
training:
  save_best_only: true

# 2. é™åˆ¶ä¿å­˜çš„æ£€æŸ¥ç‚¹æ•°é‡
training:
  max_checkpoints: 3

# 3. æ¸…ç†æ—§çš„è¾“å‡º
rm -rf outputs/old_experiment/

# 4. ä½¿ç”¨æ›´å¤§çš„ç£ç›˜
# æˆ–æŒ‚è½½å¤–éƒ¨å­˜å‚¨
```

---

## æ•°æ®åŠ è½½é—®é¢˜

### é—®é¢˜ 1: æ•°æ®é›†æ‰¾ä¸åˆ°

**ç—‡çŠ¶**:
```
FileNotFoundError: Dataset not found at /path/to/data
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥è·¯å¾„
ls /path/to/data

# 2. ä½¿ç”¨ç»å¯¹è·¯å¾„
# ç¼–è¾‘é…ç½®æ–‡ä»¶
data:
  data_dir: /absolute/path/to/data

# 3. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆæµ‹è¯•ç”¨ï¼‰
python scripts/generate_mock_data.py
```

### é—®é¢˜ 2: æ•°æ®æ ¼å¼é”™è¯¯

**ç—‡çŠ¶**:
```
ValueError: Expected CSV with columns: patient_id, image_path, label
```

**åŸå› **: CSV æ ¼å¼ä¸æ­£ç¡®

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ£€æŸ¥ CSV æ ¼å¼
import pandas as pd
df = pd.read_csv('data/metadata.csv')
print(df.columns)
print(df.head())

# ç¡®ä¿åŒ…å«å¿…éœ€çš„åˆ—
# patient_id, image_path, label
```

### é—®é¢˜ 3: å›¾åƒåŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: Error loading image: /path/to/image.nii.gz
```

**åŸå› **: å›¾åƒæ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ”¯æŒ

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. éªŒè¯å›¾åƒæ–‡ä»¶
import nibabel as nib
try:
    img = nib.load('image.nii.gz')
    print(f"Shape: {img.shape}")
except Exception as e:
    print(f"Error: {e}")

# 2. æ£€æŸ¥æ–‡ä»¶æƒé™
ls -l /path/to/image.nii.gz

# 3. é‡æ–°ä¸‹è½½æˆ–è½¬æ¢å›¾åƒ
```

### é—®é¢˜ 4: å†…å­˜æ³„æ¼

**ç—‡çŠ¶**: å†…å­˜ä½¿ç”¨æŒç»­å¢é•¿

**åŸå› **: æ•°æ®åŠ è½½å™¨æœªæ­£ç¡®æ¸…ç†

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. ä½¿ç”¨ persistent_workers
data:
  persistent_workers: true

# 2. å‡å°‘ num_workers
data:
  num_workers: 4  # ä» 16 å‡å°‘

# 3. ç¦ç”¨ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
data:
  cache_data: false
```

---

## GPU å’Œå†…å­˜é—®é¢˜

### é—®é¢˜ 1: CUDA out of memory

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. æ¸…ç† GPU ç¼“å­˜
import torch
torch.cuda.empty_cache()

# 2. å‡å° batch size
# è§è®­ç»ƒé—®é¢˜éƒ¨åˆ†

# 3. ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model = create_model(use_checkpoint=True)

# 4. ç›‘æ§å†…å­˜ä½¿ç”¨
import torch
print(f"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
print(f"Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
```

### é—®é¢˜ 2: å¤š GPU è®­ç»ƒå¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: NCCL error
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥ GPU å¯è§æ€§
nvidia-smi

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1,2,3

# 3. ä½¿ç”¨æ­£ç¡®çš„å¯åŠ¨å‘½ä»¤
torchrun --nproc_per_node=4 -m med_core.cli train --config config.yaml

# 4. æ£€æŸ¥ NCCL ç‰ˆæœ¬
python -c "import torch; print(torch.cuda.nccl.version())"
```

### é—®é¢˜ 3: GPU åˆ©ç”¨ç‡ä½

**ç—‡çŠ¶**: GPU ä½¿ç”¨ç‡ < 50%

**åŸå› **: æ•°æ®åŠ è½½ç“¶é¢ˆæˆ–æ¨¡å‹å¤ªå°

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. å¢åŠ  batch size
training:
  batch_size: 64  # å¢å¤§

# 2. å¢åŠ  data workers
data:
  num_workers: 8
  prefetch_factor: 2

# 3. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
model:
  backbone: resnet101  # ä» resnet50 å¢å¤§

# 4. å¯ç”¨æ··åˆç²¾åº¦
training:
  use_amp: true
```

---

## æ¨¡å‹é—®é¢˜

### é—®é¢˜ 1: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: Error loading checkpoint
```

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶
import torch
checkpoint = torch.load('model.pth', map_location='cpu')
print(checkpoint.keys())

# 2. ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½
model.load_state_dict(checkpoint['model_state_dict'], strict=False)

# 3. æ£€æŸ¥æ¨¡å‹æ¶æ„æ˜¯å¦åŒ¹é…
```

### é—®é¢˜ 2: é¢„è®­ç»ƒæƒé‡ä¸å…¼å®¹

**ç—‡çŠ¶**:
```
RuntimeError: size mismatch for fc.weight
```

**åŸå› **: ç±»åˆ«æ•°ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# æ–¹æ¡ˆ 1: ä¸åŠ è½½åˆ†ç±»å¤´
model:
  pretrained: true
  load_classifier: false

# æ–¹æ¡ˆ 2: ä½¿ç”¨æ­£ç¡®çš„ç±»åˆ«æ•°
model:
  num_classes: 1000  # åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹
```

### é—®é¢˜ 3: æ¨¡å‹è¾“å‡ºå½¢çŠ¶é”™è¯¯

**ç—‡çŠ¶**:
```
RuntimeError: Expected input shape (B, C, H, W), got (B, H, W, C)
```

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ£€æŸ¥è¾“å…¥å½¢çŠ¶
print(f"Input shape: {x.shape}")

# è½¬æ¢ç»´åº¦é¡ºåº
x = x.permute(0, 3, 1, 2)  # NHWC -> NCHW
```

---

## æ€§èƒ½é—®é¢˜

### é—®é¢˜ 1: æ¨ç†é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. ä½¿ç”¨ eval æ¨¡å¼
model.eval()

# 2. ç¦ç”¨æ¢¯åº¦è®¡ç®—
with torch.no_grad():
    output = model(input)

# 3. ä½¿ç”¨ TorchScript
model_scripted = torch.jit.script(model)

# 4. ä½¿ç”¨ ONNX
torch.onnx.export(model, dummy_input, "model.onnx")

# 5. ä½¿ç”¨æ‰¹å¤„ç†
# ä¸€æ¬¡å¤„ç†å¤šä¸ªæ ·æœ¬
```

### é—®é¢˜ 2: è®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**: Loss ä¸ä¸‹é™æˆ–éœ‡è¡

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# 1. è°ƒæ•´å­¦ä¹ ç‡
training:
  optimizer:
    lr: 0.0001  # é™ä½
  
  scheduler:
    type: cosine
    warmup_epochs: 5

# 2. å¢åŠ è®­ç»ƒè½®æ•°
training:
  epochs: 100  # å¢åŠ 

# 3. ä½¿ç”¨æ•°æ®å¢å¼º
data:
  augmentation:
    random_flip: true
    random_rotation: 15
    color_jitter: 0.2

# 4. æ£€æŸ¥æ•°æ®è´¨é‡
# ç¡®ä¿æ ‡ç­¾æ­£ç¡®
```

---

## Docker é—®é¢˜

### é—®é¢˜ 1: Docker æ„å»ºå¤±è´¥

**ç—‡çŠ¶**:
```
ERROR: failed to solve: process "/bin/sh -c pip install -r requirements.txt" did not complete successfully
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ¸…ç† Docker ç¼“å­˜
docker builder prune -a

# 2. æ— ç¼“å­˜æ„å»º
docker build --no-cache -t medfusion:latest .

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥
# ä½¿ç”¨é•œåƒåŠ é€Ÿå™¨

# 4. å¢åŠ æ„å»ºè¶…æ—¶
docker build --network=host -t medfusion:latest .
```

### é—®é¢˜ 2: å®¹å™¨å†… GPU ä¸å¯ç”¨

**ç—‡çŠ¶**:
```
RuntimeError: CUDA not available
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. å®‰è£… nvidia-docker
sudo apt-get install nvidia-docker2
sudo systemctl restart docker

# 2. ä½¿ç”¨ --gpus æ ‡å¿—
docker run --gpus all medfusion:latest

# 3. åœ¨ docker-compose.yml ä¸­é…ç½®
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

---

## è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
from med_core.utils.logging import setup_logging

# è®¾ç½® DEBUG çº§åˆ«
setup_logging(level="DEBUG")
```

### 2. ä½¿ç”¨ Python è°ƒè¯•å™¨

```python
# åœ¨ä»£ç ä¸­è®¾ç½®æ–­ç‚¹
import pdb; pdb.set_trace()

# æˆ–ä½¿ç”¨ ipdb
import ipdb; ipdb.set_trace()
```

### 3. æ£€æŸ¥ä¸­é—´è¾“å‡º

```python
# æ·»åŠ æ‰“å°è¯­å¥
print(f"Shape: {tensor.shape}, dtype: {tensor.dtype}")
print(f"Min: {tensor.min()}, Max: {tensor.max()}")

# ä½¿ç”¨ hook æ£€æŸ¥æ¢¯åº¦
def print_grad(grad):
    print(f"Gradient: {grad.norm()}")

tensor.register_hook(print_grad)
```

### 4. å¯è§†åŒ–æ•°æ®

```python
import matplotlib.pyplot as plt

# å¯è§†åŒ–å›¾åƒ
plt.imshow(image)
plt.show()

# å¯è§†åŒ–ç‰¹å¾å›¾
plt.imshow(feature_map[0, 0].cpu().detach().numpy())
plt.show()
```

### 5. æ€§èƒ½åˆ†æ

```python
import torch.profiler as profiler

with profiler.profile(
    activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA],
    record_shapes=True
) as prof:
    model(input)

print(prof.key_averages().table(sort_by="cuda_time_total"))
```

### 6. å†…å­˜åˆ†æ

```python
import torch

# ç›‘æ§å†…å­˜
torch.cuda.memory_summary()

# æ£€æµ‹å†…å­˜æ³„æ¼
import gc
gc.collect()
torch.cuda.empty_cache()
```

---

## è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**: æ£€æŸ¥è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
2. **æœç´¢ Issues**: åœ¨ GitHub Issues ä¸­æœç´¢ç±»ä¼¼é—®é¢˜
3. **åˆ›å»º Issue**: æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œå¤ç°æ­¥éª¤
4. **ç¤¾åŒºè®¨è®º**: åœ¨ GitHub Discussions ä¸­æé—®
5. **è”ç³»ç»´æŠ¤è€…**: å‘é€é‚®ä»¶åˆ° your-email@example.com

### æŠ¥å‘Šé—®é¢˜æ—¶è¯·åŒ…å«

- MedFusion ç‰ˆæœ¬
- Python ç‰ˆæœ¬
- PyTorch ç‰ˆæœ¬
- CUDA ç‰ˆæœ¬ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
- æ“ä½œç³»ç»Ÿ
- å®Œæ•´çš„é”™è¯¯å †æ ˆ
- æœ€å°å¯å¤ç°ç¤ºä¾‹
- é…ç½®æ–‡ä»¶

---

**æœ€åæ›´æ–°**: 2026-02-20
