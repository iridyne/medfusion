# MedFusion å¿«é€Ÿå‚è€ƒ

## å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-org/medfusion.git
cd medfusion

# å®‰è£…ä¾èµ–
uv pip install -e ".[dev]"

# éªŒè¯å®‰è£…
python -c "import med_core; print(med_core.__version__)"
```

## åŸºæœ¬ä½¿ç”¨

### è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python -m med_core.cli train --config configs/default.yaml

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python -m med_core.cli train --config configs/my_config.yaml

# æŒ‡å®šè¾“å‡ºç›®å½•
python -m med_core.cli train --config configs/default.yaml --output-dir outputs/exp1
```

### è¯„ä¼°æ¨¡å‹

```bash
# è¯„ä¼°æ£€æŸ¥ç‚¹
python -m med_core.cli evaluate --checkpoint outputs/best_model.pth

# æŒ‡å®šæ•°æ®é›†
python -m med_core.cli evaluate --checkpoint outputs/best_model.pth --data-dir data/test
```

## é…ç½®æ–‡ä»¶æ¨¡æ¿

```yaml
# configs/my_config.yaml
model:
  backbone: resnet50
  num_classes: 2
  pretrained: true

data:
  data_dir: data/
  batch_size: 32
  num_workers: 4
  image_size: 224

training:
  epochs: 100
  optimizer:
    type: adamw
    lr: 0.001
  use_amp: true
```

## å¸¸ç”¨å‘½ä»¤

### æ•°æ®å‡†å¤‡

```bash
# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
python scripts/generate_mock_data.py

# éªŒè¯æ•°æ®æ ¼å¼
python -c "from med_core.datasets import load_dataset; ds = load_dataset('data/')"
```

### æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_config_validation.py -v

# å¸¦è¦†ç›–ç‡
pytest tests/ --cov=med_core --cov-report=html
```

### ä»£ç è´¨é‡

```bash
# Linting
ruff check med_core/ tests/

# æ ¼å¼åŒ–
ruff format med_core/ tests/

# ç±»å‹æ£€æŸ¥
mypy med_core/ --ignore-missing-imports

# Pre-commit
pre-commit run --all-files
```

## Docker

```bash
# æ„å»ºé•œåƒ
docker-compose build

# è¿è¡Œè®­ç»ƒ
docker-compose up medfusion-train

# å¯åŠ¨ TensorBoard
docker-compose --profile monitoring up tensorboard

# å¯åŠ¨ Jupyter
docker-compose --profile dev up jupyter
```

## è°ƒè¯•

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export MEDCORE_LOG_LEVEL=DEBUG
python -m med_core.cli train --config configs/default.yaml

# æ£€æŸ¥ GPU
python -c "import torch; print(torch.cuda.is_available())"

# å†…å­˜åˆ†æ
python -c "import torch; print(torch.cuda.memory_summary())"
```

## é”™è¯¯ä»£ç 

| ä»£ç  | ç±»å‹ | æè¿° |
|------|------|------|
| E001-E030 | é…ç½® | é…ç½®éªŒè¯é”™è¯¯ |
| E100-E199 | é…ç½® | é…ç½®åŠ è½½é”™è¯¯ |
| E200-E299 | æ•°æ® | æ•°æ®é›†é”™è¯¯ |
| E300-E399 | æ¨¡å‹ | æ¨¡å‹é”™è¯¯ |
| E400-E499 | è®­ç»ƒ | è®­ç»ƒé”™è¯¯ |

## ç¯å¢ƒå˜é‡

```bash
# æ—¥å¿—çº§åˆ«
export MEDCORE_LOG_LEVEL=INFO

# æ•°æ®ç›®å½•
export MEDCORE_DATA_DIR=/path/to/data

# è¾“å‡ºç›®å½•
export MEDCORE_OUTPUT_DIR=/path/to/outputs

# GPU è®¾å¤‡
export CUDA_VISIBLE_DEVICES=0,1
```

## æ€§èƒ½ä¼˜åŒ–

```yaml
# æ··åˆç²¾åº¦è®­ç»ƒ
training:
  use_amp: true

# æ¢¯åº¦ç´¯ç§¯
training:
  gradient_accumulation_steps: 4

# æ•°æ®åŠ è½½ä¼˜åŒ–
data:
  num_workers: 8
  pin_memory: true
  persistent_workers: true
```

## å¸¸è§é—®é¢˜å¿«é€Ÿä¿®å¤

### CUDA out of memory
```yaml
training:
  batch_size: 8  # å‡å°
  use_amp: true  # å¯ç”¨æ··åˆç²¾åº¦
```

### Loss å˜æˆ NaN
```yaml
training:
  optimizer:
    lr: 0.0001  # é™ä½å­¦ä¹ ç‡
  max_grad_norm: 1.0  # æ¢¯åº¦è£å‰ª
```

### è®­ç»ƒé€Ÿåº¦æ…¢
```yaml
data:
  num_workers: 8  # å¢åŠ  workers
  prefetch_factor: 2
training:
  use_amp: true  # æ··åˆç²¾åº¦
```

## èµ„æºé“¾æ¥

- ğŸ“– å®Œæ•´æ–‡æ¡£: `docs/`
- ğŸ› æŠ¥å‘Šé—®é¢˜: GitHub Issues
- ğŸ’¬ è®¨è®º: GitHub Discussions
- ğŸ“§ è”ç³»: your-email@example.com

## ç‰ˆæœ¬ä¿¡æ¯

```bash
# æŸ¥çœ‹ç‰ˆæœ¬
python -c "import med_core; print(med_core.__version__)"

# æŸ¥çœ‹ä¾èµ–
uv pip list

# æ£€æŸ¥ç¯å¢ƒ
python -m med_core.cli info
```
