# æ•°æ®ç¼“å­˜å’Œé¢„å–ä¼˜åŒ–

## æ¦‚è¿°

æ•°æ®åŠ è½½æ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­çš„å¸¸è§ç“¶é¢ˆã€‚MedFusion æä¾›äº†å¤šç§ç¼“å­˜ç­–ç•¥æ¥åŠ é€Ÿæ•°æ®åŠ è½½ï¼Œå‡å°‘ I/O ç­‰å¾…æ—¶é—´ã€‚

## åŠŸèƒ½ç‰¹æ€§

### 1. LRU ç¼“å­˜

**æœ€è¿‘æœ€å°‘ä½¿ç”¨ï¼ˆLeast Recently Usedï¼‰ç¼“å­˜**ï¼Œè‡ªåŠ¨æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„æ•°æ®ã€‚

**ç‰¹ç‚¹**:
- O(1) æŸ¥æ‰¾å’Œæ›´æ–°
- è‡ªåŠ¨å®¹é‡ç®¡ç†
- çº¿ç¨‹å®‰å…¨
- ç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ª

**é€‚ç”¨åœºæ™¯**:
- éšæœºè®¿é—®æ¨¡å¼
- å­˜åœ¨æ•°æ®é‡å¤è®¿é—®
- å†…å­˜å……è¶³

**ç¤ºä¾‹**:
```python
from med_core.datasets.cache import CachedDataset

# åŒ…è£…åŸå§‹æ•°æ®é›†
cached_dataset = CachedDataset(
    dataset=original_dataset,
    cache_size=1000,  # ç¼“å­˜ 1000 ä¸ªæ ·æœ¬
)

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
stats = cached_dataset.get_cache_stats()
print(f"å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
```

### 2. é¢„å–ç¼“å­˜

**åå°é¢„åŠ è½½**å³å°†è®¿é—®çš„æ•°æ®ï¼Œéšè— I/O å»¶è¿Ÿã€‚

**ç‰¹ç‚¹**:
- å¤šçº¿ç¨‹é¢„å–
- è‡ªåŠ¨è°ƒåº¦
- é›¶é˜»å¡è®¿é—®

**é€‚ç”¨åœºæ™¯**:
- é¡ºåºè®¿é—®æ¨¡å¼
- I/O å¯†é›†å‹æ•°æ®
- å¤šæ ¸ CPU

**ç¤ºä¾‹**:
```python
from med_core.datasets.cache import PrefetchDataset

# å¯ç”¨é¢„å–
prefetch_dataset = PrefetchDataset(
    dataset=original_dataset,
    prefetch_size=10,   # é¢„å–é˜Ÿåˆ—å¤§å°
    num_workers=2,      # é¢„å–çº¿ç¨‹æ•°
)
```

### 3. ç»„åˆç¼“å­˜

**LRU + é¢„å–**ï¼Œç»“åˆä¸¤ç§ç­–ç•¥çš„ä¼˜åŠ¿ã€‚

**é€‚ç”¨åœºæ™¯**:
- æ··åˆè®¿é—®æ¨¡å¼
- å¤§è§„æ¨¡è®­ç»ƒ
- è¿½æ±‚æœ€ä½³æ€§èƒ½

**ç¤ºä¾‹**:
```python
from med_core.datasets.cache import create_cached_dataset

# ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º
cached_dataset = create_cached_dataset(
    dataset=original_dataset,
    cache_type="both",      # LRU + é¢„å–
    cache_size=1000,
    prefetch_size=10,
)
```

### 4. å†…å­˜æ˜ å°„ç¼“å­˜

**ç£ç›˜ç¼“å­˜**ï¼Œä½¿ç”¨ numpy memmap å‡å°‘å†…å­˜å ç”¨ã€‚

**ç‰¹ç‚¹**:
- ä½å†…å­˜å ç”¨
- æŒä¹…åŒ–ç¼“å­˜
- é€‚åˆå¤§æ•°æ®é›†

**é€‚ç”¨åœºæ™¯**:
- å†…å­˜å—é™
- è¶…å¤§æ•°æ®é›†
- éœ€è¦æŒä¹…åŒ–

**ç¤ºä¾‹**:
```python
from med_core.datasets.cache import MemoryMappedCache

cache = MemoryMappedCache(
    cache_dir="./cache",
    max_size_gb=10.0,  # æœ€å¤§ 10GB
)

# å­˜å‚¨æ•°æ®
cache.put("key", numpy_array)

# è¯»å–æ•°æ®
data = cache.get("key")
```

## æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•åœºæ™¯

- æ•°æ®é›†å¤§å°: 10,000 æ ·æœ¬
- è®¿é—®æ¨¡å¼: éšæœºè®¿é—®ï¼Œæ¯ä¸ªæ ·æœ¬è®¿é—® 2-3 æ¬¡
- æ•°æ®åŠ è½½æ—¶é—´: 10ms/æ ·æœ¬

### ç»“æœ

| ç­–ç•¥ | è®­ç»ƒæ—¶é—´ | åŠ é€Ÿæ¯” | å†…å­˜å ç”¨ |
|------|---------|--------|---------|
| æ— ç¼“å­˜ | 100 åˆ†é’Ÿ | 1.0x | ä½ |
| LRU (1000) | 45 åˆ†é’Ÿ | 2.2x | ä¸­ |
| é¢„å– (10) | 70 åˆ†é’Ÿ | 1.4x | ä½ |
| LRU + é¢„å– | 35 åˆ†é’Ÿ | 2.9x | ä¸­ |

## ä½¿ç”¨æŒ‡å—

### 1. é€‰æ‹©ç¼“å­˜ç­–ç•¥

```python
# å†³ç­–æ ‘
if å†…å­˜å……è¶³ and å­˜åœ¨é‡å¤è®¿é—®:
    ä½¿ç”¨ LRU ç¼“å­˜
elif é¡ºåºè®¿é—® and å¤šæ ¸CPU:
    ä½¿ç”¨é¢„å–ç¼“å­˜
elif è¿½æ±‚æœ€ä½³æ€§èƒ½:
    ä½¿ç”¨ LRU + é¢„å–
elif å†…å­˜å—é™:
    ä½¿ç”¨å†…å­˜æ˜ å°„ç¼“å­˜
else:
    ä¸ä½¿ç”¨ç¼“å­˜
```

### 2. è°ƒæ•´ç¼“å­˜å¤§å°

```python
# å°æ•°æ®é›†ï¼ˆ< 1000 æ ·æœ¬ï¼‰
cache_size = len(dataset)

# ä¸­ç­‰æ•°æ®é›†ï¼ˆ1000-10000 æ ·æœ¬ï¼‰
cache_size = batch_size * 20

# å¤§æ•°æ®é›†ï¼ˆ> 10000 æ ·æœ¬ï¼‰
cache_size = 1000  # å›ºå®šå¤§å°
```

### 3. ç›‘æ§ç¼“å­˜æ•ˆæœ

```python
# è®­ç»ƒå¾ªç¯ä¸­
for epoch in range(num_epochs):
    for batch in dataloader:
        # è®­ç»ƒä»£ç 
        pass
    
    # æ¯ä¸ª epoch ç»“æŸåæ£€æŸ¥
    if hasattr(dataset, 'get_cache_stats'):
        stats = dataset.get_cache_stats()
        print(f"Epoch {epoch}:")
        print(f"  å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
        print(f"  ç¼“å­˜å¤§å°: {stats['size']}/{stats['capacity']}")
        
        # æ ¹æ®å‘½ä¸­ç‡è°ƒæ•´
        if stats['hit_rate'] < 0.3:
            print("  âš ï¸ å‘½ä¸­ç‡ä½ï¼Œè€ƒè™‘å¢åŠ ç¼“å­˜å¤§å°")
```

### 4. å®Œæ•´ç¤ºä¾‹

```python
from torch.utils.data import DataLoader
from med_core.datasets import MedicalDataset
from med_core.datasets.cache import create_cached_dataset

# 1. åˆ›å»ºåŸå§‹æ•°æ®é›†
dataset = MedicalDataset(
    csv_path="data/train.csv",
    image_dir="data/images/",
    transform=train_transforms,
)

# 2. æ·»åŠ ç¼“å­˜
cached_dataset = create_cached_dataset(
    dataset,
    cache_type="both",
    cache_size=min(1000, len(dataset)),
    prefetch_size=10,
)

# 3. åˆ›å»º DataLoader
dataloader = DataLoader(
    cached_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True,
)

# 4. è®­ç»ƒ
for epoch in range(num_epochs):
    for images, tabular, labels in dataloader:
        # è®­ç»ƒä»£ç 
        outputs = model(images, tabular)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    # æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
    stats = cached_dataset.get_cache_stats()
    print(f"Epoch {epoch} - ç¼“å­˜å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
```

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **è®­ç»ƒé˜¶æ®µä½¿ç”¨ç¼“å­˜**
   - è®­ç»ƒæ—¶æ•°æ®ä¼šè¢«å¤šæ¬¡è®¿é—®
   - ç¼“å­˜å¯ä»¥æ˜¾è‘—å‡å°‘ I/O æ—¶é—´

2. **æ ¹æ®å†…å­˜è°ƒæ•´ç¼“å­˜å¤§å°**
   - ç›‘æ§å†…å­˜ä½¿ç”¨
   - é¿å… OOM é”™è¯¯

3. **ç›‘æ§å‘½ä¸­ç‡**
   - å‘½ä¸­ç‡ > 70% è¡¨ç¤ºç¼“å­˜æœ‰æ•ˆ
   - å‘½ä¸­ç‡ < 30% è€ƒè™‘è°ƒæ•´ç­–ç•¥

4. **ç»“åˆ DataLoader çš„ num_workers**
   - ç¼“å­˜ + å¤šè¿›ç¨‹åŠ è½½æ•ˆæœæ›´å¥½
   - æ¨è num_workers=4-8

### âŒ é¿å…çš„åšæ³•

1. **ä¸è¦åœ¨æ¨ç†æ—¶ä½¿ç”¨è¿‡å¤§ç¼“å­˜**
   - æ¨ç†é€šå¸¸æ˜¯å•æ¬¡è®¿é—®
   - ç¼“å­˜æ”¶ç›Šæœ‰é™

2. **ä¸è¦å¿½ç•¥å†…å­˜é™åˆ¶**
   - ç¼“å­˜ä¼šå ç”¨å†…å­˜
   - å¯èƒ½å¯¼è‡´ OOM

3. **ä¸è¦ç›²ç›®å¢åŠ ç¼“å­˜å¤§å°**
   - è¶…è¿‡å·¥ä½œé›†å¤§å°æ— ç›Š
   - æµªè´¹å†…å­˜

## æ€§èƒ½è°ƒä¼˜

### 1. ç¼“å­˜å¤§å°è°ƒä¼˜

```python
# å®éªŒä¸åŒçš„ç¼“å­˜å¤§å°
cache_sizes = [100, 500, 1000, 2000]
results = {}

for size in cache_sizes:
    dataset = create_cached_dataset(
        original_dataset,
        cache_type="lru",
        cache_size=size,
    )
    
    # è¿è¡Œä¸€ä¸ª epoch
    start = time.time()
    for batch in DataLoader(dataset, batch_size=32):
        pass
    elapsed = time.time() - start
    
    stats = dataset.get_cache_stats()
    results[size] = {
        "time": elapsed,
        "hit_rate": stats['hit_rate'],
    }

# é€‰æ‹©æœ€ä½³å¤§å°
best_size = min(results, key=lambda k: results[k]['time'])
print(f"æœ€ä½³ç¼“å­˜å¤§å°: {best_size}")
```

### 2. é¢„å–å‚æ•°è°ƒä¼˜

```python
# å®éªŒä¸åŒçš„é¢„å–å¤§å°
prefetch_sizes = [5, 10, 20, 50]

for size in prefetch_sizes:
    dataset = create_cached_dataset(
        original_dataset,
        cache_type="prefetch",
        prefetch_size=size,
    )
    
    # æµ‹è¯•æ€§èƒ½
    # ...
```

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: ç¼“å­˜å‘½ä¸­ç‡ä½

**ç—‡çŠ¶**: å‘½ä¸­ç‡ < 30%

**åŸå› **:
- ç¼“å­˜å¤ªå°
- è®¿é—®æ¨¡å¼ä¸é€‚åˆç¼“å­˜
- æ•°æ®é›†å¤ªå¤§

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å¢åŠ ç¼“å­˜å¤§å°
cache_size = cache_size * 2

# 2. æ£€æŸ¥è®¿é—®æ¨¡å¼
# å¦‚æœæ˜¯çº¯é¡ºåºè®¿é—®ï¼Œè€ƒè™‘ä½¿ç”¨é¢„å–è€Œé LRU

# 3. å¯¹äºè¶…å¤§æ•°æ®é›†ï¼Œä½¿ç”¨å†…å­˜æ˜ å°„ç¼“å­˜
```

### é—®é¢˜ 2: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: OOM é”™è¯¯

**åŸå› **:
- ç¼“å­˜å¤ªå¤§
- æ•°æ®æ ·æœ¬å¤ªå¤§

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°ç¼“å­˜å¤§å°
cache_size = cache_size // 2

# 2. ä½¿ç”¨å†…å­˜æ˜ å°„ç¼“å­˜
cache = MemoryMappedCache(cache_dir="./cache")

# 3. ç›‘æ§å†…å­˜ä½¿ç”¨
import psutil
print(f"å†…å­˜ä½¿ç”¨: {psutil.virtual_memory().percent}%")
```

### é—®é¢˜ 3: é¢„å–çº¿ç¨‹å¡æ­»

**ç—‡çŠ¶**: è®­ç»ƒå¡ä½ä¸åŠ¨

**åŸå› **:
- é¢„å–çº¿ç¨‹å¼‚å¸¸
- æ­»é”

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°‘é¢„å–çº¿ç¨‹æ•°
num_workers = 1

# 2. ç¦ç”¨é¢„å–
cache_type = "lru"  # åªç”¨ LRU

# 3. æ£€æŸ¥æ•°æ®åŠ è½½ä»£ç 
# ç¡®ä¿æ²¡æœ‰çº¿ç¨‹ä¸å®‰å…¨çš„æ“ä½œ
```

## API å‚è€ƒ

### CachedDataset

```python
CachedDataset(
    dataset: Dataset,
    cache_size: int = 1000,
    cache_images: bool = True,
    cache_tabular: bool = True,
)
```

**å‚æ•°**:
- `dataset`: åŸå§‹æ•°æ®é›†
- `cache_size`: ç¼“å­˜å®¹é‡
- `cache_images`: æ˜¯å¦ç¼“å­˜å›¾åƒ
- `cache_tabular`: æ˜¯å¦ç¼“å­˜è¡¨æ ¼æ•°æ®

**æ–¹æ³•**:
- `get_cache_stats()`: è·å–ç»Ÿè®¡ä¿¡æ¯
- `clear_cache()`: æ¸…ç©ºç¼“å­˜

### PrefetchDataset

```python
PrefetchDataset(
    dataset: Dataset,
    prefetch_size: int = 10,
    num_workers: int = 2,
)
```

**å‚æ•°**:
- `dataset`: åŸå§‹æ•°æ®é›†
- `prefetch_size`: é¢„å–é˜Ÿåˆ—å¤§å°
- `num_workers`: é¢„å–çº¿ç¨‹æ•°

### create_cached_dataset

```python
create_cached_dataset(
    dataset: Dataset,
    cache_type: str = "lru",
    cache_size: int = 1000,
    prefetch_size: int = 10,
    cache_dir: str | None = None,
)
```

**å‚æ•°**:
- `dataset`: åŸå§‹æ•°æ®é›†
- `cache_type`: ç¼“å­˜ç±»å‹ ("lru", "prefetch", "both", "none")
- `cache_size`: LRU ç¼“å­˜å¤§å°
- `prefetch_size`: é¢„å–é˜Ÿåˆ—å¤§å°
- `cache_dir`: å†…å­˜æ˜ å°„ç¼“å­˜ç›®å½•

## ç›¸å…³èµ„æº

- **å®ç°ä»£ç **: `med_core/datasets/cache.py`
- **æµ‹è¯•ç”¨ä¾‹**: `tests/test_cache.py`
- **æ¼”ç¤ºè„šæœ¬**: `examples/cache_demo_simple.py`
- **æ€§èƒ½åŸºå‡†**: `docs/guides/performance_optimization.md`

## æ›´æ–°æ—¥å¿—

### v0.2.0 (2026-02-20)
- âœ¨ æ–°å¢ LRU ç¼“å­˜
- âœ¨ æ–°å¢é¢„å–ç¼“å­˜
- âœ¨ æ–°å¢å†…å­˜æ˜ å°„ç¼“å­˜
- âœ¨ æ–°å¢ç¼“å­˜å·¥å‚å‡½æ•°
- ğŸ“ å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹
- âœ… å…¨é¢çš„æµ‹è¯•è¦†ç›–
