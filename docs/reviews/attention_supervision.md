# æ³¨æ„åŠ›ç›‘ç£æ¡†æž¶å®¡æŸ¥æŠ¥å‘Š

**å®¡æŸ¥æ—¥æœŸ**: 2026-02-13  
**å®¡æŸ¥èŒƒå›´**: commit cd3ebce - "feat(attention): add offline attention supervision framework"  
**å®¡æŸ¥äºº**: AI Assistant

---

## ðŸ“‹ æ‰§è¡Œæ‘˜è¦

### å®¡æŸ¥ç»“è®º

**æ€»ä½“è¯„ä»·**: âš ï¸ **éƒ¨åˆ†åˆç†ï¼Œä½†å­˜åœ¨ä¸¥é‡é—®é¢˜**

**æ ¸å¿ƒé—®é¢˜**:
1. âŒ **æž¶æž„ä¸åŒ¹é…** - Med-Framework çŽ°æœ‰æ¨¡åž‹æ²¡æœ‰å¯ç›‘ç£çš„æ³¨æ„åŠ›æƒé‡è¾“å‡º
2. âŒ **é›†æˆç¼ºå¤±** - ç¼ºå°‘å°†æ³¨æ„åŠ›ç›‘ç£é›†æˆåˆ°è®­ç»ƒæµç¨‹çš„ä»£ç 
3. âš ï¸ **æ„å¤–æ–‡ä»¶** - æäº¤äº† 4.4MB çš„ zod PostScript æ–‡ä»¶
4. âš ï¸ **åŠŸèƒ½é‡å¤** - çŽ°æœ‰ CBAM/SE/ECA æ³¨æ„åŠ›æœºåˆ¶ä¸Žæ–°æ¨¡å—å…³ç³»ä¸æ¸…

**å»ºè®®**: éœ€è¦é‡å¤§ä¿®æ”¹æ‰èƒ½ä½¿ç”¨

---

## ðŸ” è¯¦ç»†å®¡æŸ¥

### 1. æž¶æž„è®¾è®¡å®¡æŸ¥

#### âœ… ä¼˜ç‚¹

1. **æ¨¡å—åŒ–è®¾è®¡è‰¯å¥½**
   - æ¸…æ™°çš„æŠ½è±¡åŸºç±» `BaseAttentionSupervision`
   - ä¸‰ç§ç›‘ç£æ–¹æ³•ç‹¬ç«‹å®žçŽ°ï¼ˆMask/CAM/MILï¼‰
   - ç»Ÿä¸€çš„ `AttentionLoss` è¿”å›žæ ¼å¼

2. **ä»£ç è´¨é‡é«˜**
   - å®Œæ•´çš„ç±»åž‹æ³¨è§£
   - è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
   - è¯­æ³•æ£€æŸ¥å…¨éƒ¨é€šè¿‡

3. **é…ç½®ç³»ç»Ÿå®Œå–„**
   - `AttentionSupervisionConfig` æ”¯æŒæ‰€æœ‰å‚æ•°
   - é¢„è®¾é…ç½®å·¥åŽ‚å‡½æ•°
   - ä¸ŽçŽ°æœ‰é…ç½®ç³»ç»Ÿé£Žæ ¼ä¸€è‡´

#### âŒ ä¸¥é‡é—®é¢˜

**é—®é¢˜ 1: æž¶æž„ä¸åŒ¹é… - çŽ°æœ‰æ¨¡åž‹æ²¡æœ‰æ³¨æ„åŠ›æƒé‡è¾“å‡º**

Med-Framework çš„çŽ°æœ‰æ¨¡åž‹æž¶æž„ï¼š

```python
# çŽ°æœ‰çš„ Vision Backbone
class ResNetBackbone(BaseVisionBackbone):
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        features = self.backbone(x)  # (B, C, H, W)
        if self.attention is not None:
            features = self.attention(features)  # CBAM/SE/ECA ç›´æŽ¥ä¿®æ”¹ç‰¹å¾
        pooled = self.pool(features)  # (B, C)
        return self.projection(pooled)  # (B, feature_dim)
```

**é—®é¢˜**: 
- CBAM/SE/ECA æ³¨æ„åŠ›æœºåˆ¶æ˜¯**é€šé“æ³¨æ„åŠ›**å’Œ**ç©ºé—´æ³¨æ„åŠ›**ï¼Œå®ƒä»¬ç›´æŽ¥ä¿®æ”¹ç‰¹å¾å›¾ï¼Œ**ä¸è¿”å›žå¯ç›‘ç£çš„æ³¨æ„åŠ›æƒé‡**
- çŽ°æœ‰æ¨¡åž‹çš„ `forward()` åªè¿”å›žç‰¹å¾å‘é‡ `(B, feature_dim)`ï¼Œæ²¡æœ‰è¿”å›žç©ºé—´æ³¨æ„åŠ›å›¾ `(B, H, W)`

**ä½ çš„æ³¨æ„åŠ›ç›‘ç£æ¨¡å—æœŸæœ›**:

```python
# ä½ çš„ä»£ç æœŸæœ›
attention_weights = model.get_attention_weights(images)  # (B, H, W) æˆ– (B, 1, H, W)
loss_result = supervision(
    attention_weights=attention_weights,  # âŒ çŽ°æœ‰æ¨¡åž‹æ— æ³•æä¾›è¿™ä¸ª
    features=features,
    ...
)
```

**ç»“è®º**: **æ— æ³•ç›´æŽ¥ä½¿ç”¨**ï¼Œéœ€è¦ä¿®æ”¹çŽ°æœ‰æ¨¡åž‹æž¶æž„ã€‚

---

**é—®é¢˜ 2: é›†æˆä»£ç ç¼ºå¤±**

ä½ åˆ›å»ºäº†æ³¨æ„åŠ›ç›‘ç£æ¨¡å—ï¼Œä½†**æ²¡æœ‰ä¿®æ”¹è®­ç»ƒå™¨**æ¥å®žé™…ä½¿ç”¨å®ƒï¼š

```python
# çŽ°æœ‰çš„ MultimodalTrainer.training_step()
def training_step(self, batch, batch_idx):
    images, tabular, labels = batch
    outputs = self.model(images, tabular)
    loss = self.criterion(outputs["logits"], labels)
    # âŒ æ²¡æœ‰è°ƒç”¨æ³¨æ„åŠ›ç›‘ç£
    return loss
```

**ç¼ºå¤±çš„é›†æˆä»£ç **:
1. ä¿®æ”¹æ¨¡åž‹ä½¿å…¶è¿”å›žæ³¨æ„åŠ›æƒé‡
2. åœ¨è®­ç»ƒæ­¥éª¤ä¸­è°ƒç”¨æ³¨æ„åŠ›ç›‘ç£
3. å°†æ³¨æ„åŠ›æŸå¤±åŠ åˆ°æ€»æŸå¤±ä¸­
4. è®°å½•æ³¨æ„åŠ›å¯è§†åŒ–

---

**é—®é¢˜ 3: CAM æ–¹æ³•çš„é€‚ç”¨æ€§é—®é¢˜**

ä½ çš„ CAM è‡ªç›‘ç£æ–¹æ³•ï¼š

```python
def generate_cam(
    feature_maps: torch.Tensor,  # (B, C, H, W)
    classifier_weights: torch.Tensor,  # (num_classes, C)
    predicted_class: torch.Tensor | None = None,
) -> torch.Tensor:
    # ç”Ÿæˆ CAM
    cam = (classifier_weights.view(C, 1, 1) * feature_maps).sum(0)
    return cam  # (B, H, W)
```

**é—®é¢˜**:
- è¿™ä¸ªæ–¹æ³•å‡è®¾åˆ†ç±»å™¨æ˜¯ `Linear(C, num_classes)`ï¼Œç›´æŽ¥ä½œç”¨äºŽå…¨å±€å¹³å‡æ± åŒ–åŽçš„ç‰¹å¾
- ä½† Med-Framework çš„æ¨¡åž‹æž¶æž„æ˜¯ï¼š
  ```python
  features = backbone(images)  # (B, feature_dim) - å·²ç»æ± åŒ–äº†ï¼
  logits = classifier(features)  # (B, num_classes)
  ```
- **ç‰¹å¾å·²ç»è¢«å…¨å±€æ± åŒ–**ï¼Œç©ºé—´ä¿¡æ¯ä¸¢å¤±ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„ CAM

**éœ€è¦çš„ä¿®æ”¹**:
- åœ¨æ± åŒ–ä¹‹å‰ä¿å­˜ç‰¹å¾å›¾ `(B, C, H, W)`
- ä¿®æ”¹æ¨¡åž‹è¿”å›žä¸­é—´ç‰¹å¾å›¾

---

### 2. ä»£ç å®žçŽ°å®¡æŸ¥

#### âœ… æ­£ç¡®çš„éƒ¨åˆ†

1. **æŸå¤±å‡½æ•°å®žçŽ°æ­£ç¡®**
   - `AttentionConsistencyLoss` - ç†µ/æ–¹å·®/åŸºå°¼ç³»æ•°è®¡ç®—æ­£ç¡®
   - `AttentionSmoothLoss` - Total Variation å®žçŽ°æ­£ç¡®
   - KL æ•£åº¦å¯¹é½æŸå¤±ä½¿ç”¨æ­£ç¡®

2. **å·¥å…·å‡½æ•°å®žçŽ°æ­£ç¡®**
   - `mask_to_attention_target()` - æŽ©ç è½¬æ¢é€»è¾‘æ­£ç¡®
   - `normalize_attention()` - å½’ä¸€åŒ–æ–¹æ³•æ­£ç¡®
   - `resize_target()` - å°ºå¯¸è°ƒæ•´æ­£ç¡®

3. **æ•°æ®é›†æ‰©å±•åˆç†**
   - `AttentionSupervisedDataset` æ­£ç¡®ç»§æ‰¿ `BaseMultimodalDataset`
   - æ”¯æŒæŽ©ç /è¾¹ç•Œæ¡†/å…³é”®ç‚¹åŠ è½½

#### âš ï¸ æ½œåœ¨é—®é¢˜

**é—®é¢˜ 1: MIL å®žçŽ°ä¸å®Œæ•´**

```python
# med_core/attention_supervision/mil_supervision.py
class MultiInstanceLearning(nn.Module):
    def forward(self, patches: torch.Tensor) -> torch.Tensor:
        # å®žçŽ°äº† MIL æ³¨æ„åŠ›è®¡ç®—
        ...
```

**é—®é¢˜**: 
- MIL æ¨¡å—æ˜¯ç‹¬ç«‹çš„ï¼Œä½†**æ²¡æœ‰é›†æˆåˆ°ä¸»æ¨¡åž‹ä¸­**
- ç¼ºå°‘ `extract_patches()` å‡½æ•°çš„å®žçŽ°ï¼ˆè™½ç„¶åœ¨ `__init__.py` ä¸­å¯¼å‡ºäº†ï¼‰
- ä¸æ¸…æ¥šå¦‚ä½•åœ¨è®­ç»ƒæ—¶ä½¿ç”¨

---

**é—®é¢˜ 2: é…ç½®ç±»å†—ä½™**

ä½ åˆ›å»ºäº†æ–°çš„é…ç½®ç±»ï¼š
- `DataConfigWithMask`
- `TrainingConfigWithAttention`
- `ExperimentConfigWithAttention`

ä½†è¿™äº›ä¸ŽçŽ°æœ‰é…ç½®ç³»ç»Ÿ**å¹³è¡Œå­˜åœ¨**ï¼Œæ²¡æœ‰é›†æˆï¼š

```python
# çŽ°æœ‰é…ç½®
from med_core.configs import ExperimentConfig

# ä½ çš„æ–°é…ç½®
from med_core.configs.attention_config import ExperimentConfigWithAttention

# âŒ ç”¨æˆ·éœ€è¦é€‰æ‹©ä½¿ç”¨å“ªä¸ªï¼Ÿä¼šé€ æˆæ··ä¹±
```

**å»ºè®®**: åº”è¯¥æ‰©å±•çŽ°æœ‰é…ç½®ç±»ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°çš„ã€‚

---

### 3. ä¸ŽçŽ°æœ‰æ¡†æž¶çš„é›†æˆå®¡æŸ¥

#### âŒ é›†æˆé—®é¢˜

**é—®é¢˜ 1: ä¸ŽçŽ°æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„å…³ç³»ä¸æ¸…**

Med-Framework å·²æœ‰æ³¨æ„åŠ›æœºåˆ¶ï¼š
- `CBAM` (Convolutional Block Attention Module)
- `SE` (Squeeze-and-Excitation)
- `ECA` (Efficient Channel Attention)

ä½ çš„æ³¨æ„åŠ›ç›‘ç£æ¨¡å—ï¼š
- ç›‘ç£**ç©ºé—´æ³¨æ„åŠ›æƒé‡** `(B, H, W)`

**å…³ç³»ä¸æ¸…**:
- CBAM æœ‰ç©ºé—´æ³¨æ„åŠ›åˆ†æ”¯ï¼Œä½†ä¸è¿”å›žæƒé‡
- SE/ECA åªæœ‰é€šé“æ³¨æ„åŠ›ï¼Œæ²¡æœ‰ç©ºé—´æ³¨æ„åŠ›
- ä½ çš„ç›‘ç£æ¨¡å—å¦‚ä½•ä¸Žå®ƒä»¬é…åˆï¼Ÿ

**éœ€è¦æ˜Žç¡®**:
1. æ˜¯å¦éœ€è¦ä¿®æ”¹ CBAM ä½¿å…¶è¿”å›žç©ºé—´æ³¨æ„åŠ›æƒé‡ï¼Ÿ
2. æ˜¯å¦éœ€è¦æ·»åŠ æ–°çš„æ³¨æ„åŠ›æ¨¡å—ä¸“é—¨ç”¨äºŽç›‘ç£ï¼Ÿ
3. è¿˜æ˜¯å®Œå…¨ç‹¬ç«‹çš„æ³¨æ„åŠ›åˆ†æ”¯ï¼Ÿ

---

**é—®é¢˜ 2: è®­ç»ƒæµç¨‹æœªä¿®æ”¹**

çŽ°æœ‰è®­ç»ƒå™¨ `MultimodalTrainer` å’Œ `MultiViewMultimodalTrainer` **å®Œå…¨æ²¡æœ‰ä¿®æ”¹**ï¼Œæ— æ³•ä½¿ç”¨æ³¨æ„åŠ›ç›‘ç£ã€‚

éœ€è¦çš„ä¿®æ”¹ï¼š

```python
# åº”è¯¥ä¿®æ”¹çš„åœ°æ–¹
class MultimodalTrainer(BaseTrainer):
    def __init__(self, ..., attention_supervision=None):
        self.attention_supervision = attention_supervision
    
    def training_step(self, batch, batch_idx):
        images, tabular, labels = batch
        
        # éœ€è¦ä¿®æ”¹æ¨¡åž‹è¿”å›žæ³¨æ„åŠ›æƒé‡
        outputs = self.model(images, tabular, return_attention=True)
        
        # åˆ†ç±»æŸå¤±
        cls_loss = self.criterion(outputs["logits"], labels)
        
        # æ³¨æ„åŠ›ç›‘ç£æŸå¤±
        if self.attention_supervision is not None:
            att_loss = self.attention_supervision(
                attention_weights=outputs["attention"],
                features=outputs["features"],
                ...
            )
            total_loss = cls_loss + att_loss.total_loss
        else:
            total_loss = cls_loss
        
        return total_loss
```

**å½“å‰çŠ¶æ€**: è¿™äº›ä¿®æ”¹**å®Œå…¨ç¼ºå¤±**ã€‚

---

### 4. æ„å¤–æ–‡ä»¶å®¡æŸ¥

#### âŒ ä¸¥é‡é—®é¢˜: zod æ–‡ä»¶

```bash
$ git diff HEAD~1 --stat
 zod | 58649 ++++++++++++++++++++++++++
```

**é—®é¢˜**:
- æäº¤äº†ä¸€ä¸ª 4.4MB çš„ PostScript æ–‡ä»¶ `zod`
- è¿™æ˜¯ä¸€ä¸ª**å›¾å½¢æ–‡ä»¶**ï¼ˆå¯èƒ½æ˜¯å¯è§†åŒ–è¾“å‡ºï¼‰
- **ä¸åº”è¯¥æäº¤åˆ°ä»£ç ä»“åº“**

**æ–‡ä»¶å†…å®¹**:
```postscript
%!PS-Adobe-3.0
%%Creator: (ImageMagick)
%%Title: (zod)
%%CreationDate: (2026-02-13T06:58:41+00:00)
%%Pages: 5
```

**å»ºè®®**: 
1. ç«‹å³ä»Ž Git åŽ†å²ä¸­ç§»é™¤
2. æ·»åŠ åˆ° `.gitignore`
3. ä½¿ç”¨ `git filter-branch` æˆ– `git rebase` æ¸…ç†

---

### 5. æ–‡æ¡£å®¡æŸ¥

#### âœ… æ–‡æ¡£è´¨é‡é«˜

1. **ATTENTION_SUPERVISION_GUIDE.md** (727 è¡Œ)
   - è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—
   - 4 ä¸ªå®Œæ•´ç¤ºä¾‹
   - é…ç½®è¯´æ˜Žæ¸…æ™°
   - å¯è§†åŒ–æ•™ç¨‹å®Œæ•´

2. **ä»£ç æ–‡æ¡£å­—ç¬¦ä¸²**
   - æ‰€æœ‰ç±»å’Œå‡½æ•°éƒ½æœ‰æ–‡æ¡£
   - å‚æ•°è¯´æ˜Žå®Œæ•´
   - åŒ…å«ä½¿ç”¨ç¤ºä¾‹

#### âš ï¸ æ–‡æ¡£é—®é¢˜

**é—®é¢˜**: æ–‡æ¡£ä¸­çš„ç¤ºä¾‹ä»£ç **æ— æ³•è¿è¡Œ**ï¼Œå› ä¸ºï¼š
1. çŽ°æœ‰æ¨¡åž‹ä¸è¿”å›žæ³¨æ„åŠ›æƒé‡
2. è®­ç»ƒå™¨æ²¡æœ‰é›†æˆæ³¨æ„åŠ›ç›‘ç£
3. é…ç½®ç³»ç»Ÿæ²¡æœ‰é›†æˆ

**ç¤ºä¾‹**:
```python
# æ–‡æ¡£ä¸­çš„ç¤ºä¾‹
supervision = CAMSelfSupervision(loss_weight=0.1)
features = backbone(images)
attention = attention_module(features)  # âŒ è¿™ä¸ªæ¨¡å—ä¸å­˜åœ¨

loss_result = supervision(
    attention_weights=attention,  # âŒ æ— æ³•èŽ·å–
    features=features,
    classifier_weights=model.classifier.weight,
)
```

---

## ðŸŽ¯ å¿…è¦æ€§è¯„ä¼°

### åŠŸèƒ½æ˜¯å¦å¿…è¦ï¼Ÿ

**å›žç­”**: âš ï¸ **æœ‰ä»·å€¼ï¼Œä½†å®žçŽ°æ–¹å¼æœ‰é—®é¢˜**

#### æœ‰ä»·å€¼çš„åŽŸå› 

1. **åŒ»å­¦å½±åƒçš„å¯è§£é‡Šæ€§éœ€æ±‚**
   - åŒ»ç”Ÿéœ€è¦çŸ¥é“æ¨¡åž‹å…³æ³¨å“ªé‡Œ
   - æ³¨æ„åŠ›ç›‘ç£å¯ä»¥å¼•å¯¼æ¨¡åž‹å…³æ³¨ç—…ç¶

2. **CAM æ–¹æ³•çš„å®žç”¨æ€§**
   - åœ¨æ²¡æœ‰æŽ©ç æ ‡æ³¨æ—¶ï¼ŒCAM å¯ä»¥è‡ªåŠ¨ç”Ÿæˆçƒ­åŠ›å›¾
   - é™ä½Žæ ‡æ³¨æˆæœ¬

3. **å¤šç§ç›‘ç£æ–¹æ³•**
   - æŽ©ç ç›‘ç£ï¼ˆæœ€ç²¾ç¡®ï¼‰
   - CAM è‡ªç›‘ç£ï¼ˆæ— éœ€æ ‡æ³¨ï¼‰
   - MILï¼ˆè‡ªåŠ¨å®šä½ï¼‰
   - è¦†ç›–ä¸åŒæ•°æ®é›†åœºæ™¯

#### é—®é¢˜åœ¨äºŽå®žçŽ°æ–¹å¼

1. **æ²¡æœ‰è€ƒè™‘çŽ°æœ‰æž¶æž„**
   - çŽ°æœ‰æ¨¡åž‹ä¸æ”¯æŒè¿”å›žæ³¨æ„åŠ›æƒé‡
   - éœ€è¦å…ˆä¿®æ”¹æ¨¡åž‹æž¶æž„

2. **é›†æˆå·¥ä½œç¼ºå¤±**
   - åªå®žçŽ°äº†ç›‘ç£æ¨¡å—ï¼Œæ²¡æœ‰é›†æˆåˆ°è®­ç»ƒæµç¨‹
   - ç”¨æˆ·æ— æ³•ç›´æŽ¥ä½¿ç”¨

3. **åŠŸèƒ½é‡å¤**
   - çŽ°æœ‰ CBAM/SE/ECA æ³¨æ„åŠ›æœºåˆ¶
   - æ–°æ¨¡å—ä¸Žå®ƒä»¬çš„å…³ç³»ä¸æ¸…

---

## ðŸ“Š æ­£ç¡®æ€§è¯„ä¼°

### ä»£ç æ­£ç¡®æ€§

| æ¨¡å— | æ­£ç¡®æ€§ | è¯´æ˜Ž |
|------|--------|------|
| `base.py` | âœ… æ­£ç¡® | æŠ½è±¡åŸºç±»è®¾è®¡åˆç†ï¼Œå·¥å…·å‡½æ•°å®žçŽ°æ­£ç¡® |
| `cam_supervision.py` | âš ï¸ éƒ¨åˆ†æ­£ç¡® | CAM ç”Ÿæˆé€»è¾‘æ­£ç¡®ï¼Œä½†å‡è®¾ä¸ç¬¦åˆçŽ°æœ‰æž¶æž„ |
| `mask_supervision.py` | âœ… æ­£ç¡® | æŽ©ç ç›‘ç£å®žçŽ°æ­£ç¡® |
| `mil_supervision.py` | âš ï¸ ä¸å®Œæ•´ | MIL å®žçŽ°æ­£ç¡®ï¼Œä½†ç¼ºå°‘é›†æˆä»£ç  |
| `attention_supervised.py` | âœ… æ­£ç¡® | æ•°æ®é›†æ‰©å±•å®žçŽ°æ­£ç¡® |
| `attention_config.py` | âš ï¸ å†—ä½™ | é…ç½®ç±»æ­£ç¡®ï¼Œä½†ä¸ŽçŽ°æœ‰ç³»ç»Ÿå¹³è¡Œå­˜åœ¨ |
| `attention_viz.py` | âœ… æ­£ç¡® | å¯è§†åŒ–å‡½æ•°å®žçŽ°æ­£ç¡® |

### æž¶æž„æ­£ç¡®æ€§

| æ–¹é¢ | è¯„ä¼° | è¯´æ˜Ž |
|------|------|------|
| æ¨¡å—åŒ–è®¾è®¡ | âœ… ä¼˜ç§€ | æ¸…æ™°çš„æŠ½è±¡å’Œå®žçŽ°åˆ†ç¦» |
| æŽ¥å£è®¾è®¡ | âœ… è‰¯å¥½ | ç»Ÿä¸€çš„ `forward()` æŽ¥å£ |
| ä¸ŽçŽ°æœ‰æ¡†æž¶é›†æˆ | âŒ å¤±è´¥ | æ²¡æœ‰è€ƒè™‘çŽ°æœ‰æ¨¡åž‹æž¶æž„ |
| å¯æ‰©å±•æ€§ | âœ… è‰¯å¥½ | æ˜“äºŽæ·»åŠ æ–°çš„ç›‘ç£æ–¹æ³• |
| å¯ç”¨æ€§ | âŒ ä¸å¯ç”¨ | ç¼ºå°‘é›†æˆä»£ç ï¼Œæ— æ³•ç›´æŽ¥ä½¿ç”¨ |

---

## ðŸ”§ ä¿®å¤å»ºè®®

### ä¼˜å…ˆçº§ 1: å¿…é¡»ä¿®å¤ï¼ˆé˜»å¡žæ€§é—®é¢˜ï¼‰

#### 1. ç§»é™¤ zod æ–‡ä»¶

```bash
# ä»Žå½“å‰æäº¤ä¸­ç§»é™¤
git rm zod
git commit --amend --no-edit

# ä»ŽåŽ†å²ä¸­ç§»é™¤ï¼ˆå¦‚æžœå·²ç»æŽ¨é€ï¼‰
git filter-branch --force --index-filter \
  'git rm --cached --ignore-unmatch zod' \
  --prune-empty --tag-name-filter cat -- --all
```

#### 2. ä¿®æ”¹æ¨¡åž‹æž¶æž„ä»¥è¿”å›žæ³¨æ„åŠ›æƒé‡

**é€‰é¡¹ A: ä¿®æ”¹çŽ°æœ‰ CBAM æ¨¡å—**

```python
# med_core/backbones/attention.py
class SpatialAttention(nn.Module):
    def forward(self, x: torch.Tensor, return_weights: bool = False):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        concat = torch.cat([avg_out, max_out], dim=1)
        attention_weights = self.sigmoid(self.conv(concat))  # (B, 1, H, W)
        
        if return_weights:
            return x * attention_weights, attention_weights
        else:
            return x * attention_weights
```

**é€‰é¡¹ B: æ·»åŠ ç‹¬ç«‹çš„æ³¨æ„åŠ›åˆ†æ”¯**

```python
# med_core/backbones/vision.py
class ResNetBackbone(BaseVisionBackbone):
    def __init__(self, ..., use_attention_supervision=False):
        super().__init__(...)
        if use_attention_supervision:
            self.attention_head = nn.Sequential(
                nn.Conv2d(self._backbone_out_dim, 128, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(128, 1, 1),
                nn.Sigmoid(),
            )
    
    def forward(self, x, return_attention=False):
        features = self.backbone(x)  # (B, C, H, W)
        
        attention_weights = None
        if return_attention and hasattr(self, 'attention_head'):
            attention_weights = self.attention_head(features)  # (B, 1, H, W)
        
        pooled = self.pool(features)  # (B, C)
        output = self.projection(pooled)  # (B, feature_dim)
        
        if return_attention:
            return output, features, attention_weights
        else:
            return output
```

#### 3. é›†æˆåˆ°è®­ç»ƒå™¨

```python
# med_core/trainers/multimodal.py
class MultimodalTrainer(BaseTrainer):
    def __init__(
        self,
        model,
        criterion,
        optimizer,
        attention_supervision=None,  # æ–°å¢žå‚æ•°
        ...
    ):
        super().__init__(...)
        self.attention_supervision = attention_supervision
    
    def training_step(self, batch, batch_idx):
        images, tabular, labels = batch
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨æ³¨æ„åŠ›ç›‘ç£å†³å®šè¿”å›žæ ¼å¼
        if self.attention_supervision is not None:
            vision_features, feature_maps, attention_weights = self.model.vision_backbone(
                images, return_attention=True
            )
            tabular_features = self.model.tabular_backbone(tabular)
            fused, _ = self.model.fusion_module(vision_features, tabular_features)
            logits = self.model.classifier(fused)
            
            # åˆ†ç±»æŸå¤±
            cls_loss = self.criterion(logits, labels)
            
            # æ³¨æ„åŠ›ç›‘ç£æŸå¤±
            att_loss_result = self.attention_supervision(
                attention_weights=attention_weights,
                features=feature_maps,
                classifier_weights=self.model.classifier.weight,
                predicted_class=logits.argmax(dim=1),
            )
            
            total_loss = cls_loss + att_loss_result.total_loss
            
            # è®°å½•
            self.log("train/cls_loss", cls_loss)
            self.log("train/att_loss", att_loss_result.total_loss)
            for key, value in att_loss_result.components.items():
                self.log(f"train/att_{key}", value)
        else:
            outputs = self.model(images, tabular)
            total_loss = self.criterion(outputs["logits"], labels)
        
        return total_loss
```

---

### ä¼˜å…ˆçº§ 2: åº”è¯¥ä¿®å¤ï¼ˆåŠŸèƒ½æ€§é—®é¢˜ï¼‰

#### 4. ä¿®å¤ CAM æ–¹æ³•ä»¥é€‚é…çŽ°æœ‰æž¶æž„

```python
# med_core/attention_supervision/cam_supervision.py
def generate_cam(
    feature_maps: torch.Tensor,  # (B, C, H, W) - æ± åŒ–å‰çš„ç‰¹å¾å›¾
    classifier_weights: torch.Tensor,  # (num_classes, feature_dim)
    projection_weights: torch.Tensor,  # (feature_dim, C) - æŠ•å½±å±‚æƒé‡
    predicted_class: torch.Tensor | None = None,
) -> torch.Tensor:
    """
    ç”Ÿæˆ CAMï¼Œé€‚é… Med-Framework çš„æž¶æž„
    
    Med-Framework æž¶æž„:
    features (B, C, H, W) -> pool -> (B, C) -> projection -> (B, feature_dim) -> classifier -> (B, num_classes)
    
    éœ€è¦åå‘ä¼ æ’­æƒé‡:
    classifier_weights (num_classes, feature_dim) @ projection_weights (feature_dim, C) = (num_classes, C)
    """
    B, C, H, W = feature_maps.shape
    
    # ç»„åˆåˆ†ç±»å™¨å’ŒæŠ•å½±å±‚çš„æƒé‡
    combined_weights = torch.matmul(
        classifier_weights,  # (num_classes, feature_dim)
        projection_weights,  # (feature_dim, C)
    )  # (num_classes, C)
    
    if predicted_class is None:
        pooled = F.adaptive_avg_pool2d(feature_maps, 1).squeeze(-1).squeeze(-1)
        projected = F.linear(pooled, projection_weights.T)
        logits = F.linear(projected, classifier_weights)
        predicted_class = logits.argmax(dim=1)
    
    cam = torch.zeros(B, H, W, device=feature_maps.device)
    for i in range(B):
        class_weights = combined_weights[predicted_class[i]]  # (C,)
        cam[i] = (class_weights.view(C, 1, 1) * feature_maps[i]).sum(0)
    
    cam = F.relu(cam)
    for i in range(B):
        max_val = cam[i].max()
        if max_val > 0:
            cam[i] = cam[i] / max_val
    
    return cam
```

#### 5. æ•´åˆé…ç½®ç³»ç»Ÿ

```python
# med_core/configs/base_config.py
from dataclasses import dataclass, field

@dataclass
class VisionConfig:
    # çŽ°æœ‰å­—æ®µ...
    
    # æ–°å¢žæ³¨æ„åŠ›ç›‘ç£ç›¸å…³å­—æ®µ
    use_attention_supervision: bool = False
    attention_supervision_method: str = "none"  # "mask", "cam", "mil", "none"
    attention_loss_weight: float = 0.1

@dataclass
class TrainingConfig:
    # çŽ°æœ‰å­—æ®µ...
    
    # æ–°å¢žæ³¨æ„åŠ›ç›‘ç£é…ç½®
    log_attention_every: int = 100
    save_attention_maps: bool = False
```

**ä¸è¦åˆ›å»ºæ–°çš„é…ç½®ç±»**ï¼Œè€Œæ˜¯æ‰©å±•çŽ°æœ‰çš„ã€‚

---

### ä¼˜å…ˆçº§ 3: å»ºè®®ä¿®å¤ï¼ˆæ”¹è¿›æ€§é—®é¢˜ï¼‰

#### 6. æ·»åŠ å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹

åˆ›å»º `examples/attention_supervision_example.py`:

```python
"""
å®Œæ•´çš„æ³¨æ„åŠ›ç›‘ç£è®­ç»ƒç¤ºä¾‹
"""
import torch
from med_core.configs import ExperimentConfig, VisionConfig, TrainingConfig
from med_core.datasets import MedicalMultimodalDataset
from med_core.fusion import create_fusion_model
from med_core.trainers import MultimodalTrainer
from med_core.attention_supervision import CAMSelfSupervision

# 1. é…ç½®
config = ExperimentConfig(
    experiment_name="pneumonia_with_attention",
    model=ModelConfig(
        vision=VisionConfig(
            backbone_name="resnet50",
            use_attention_supervision=True,  # å¯ç”¨æ³¨æ„åŠ›ç›‘ç£
            attention_supervision_method="cam",
        ),
    ),
    training=TrainingConfig(
        log_attention_every=50,
        save_attention_maps=True,
    ),
)

# 2. æ•°æ®
dataset = MedicalMultimodalDataset.from_csv(...)

# 3. æ¨¡åž‹
model = create_fusion_model(config.model)

# 4. æ³¨æ„åŠ›ç›‘ç£
attention_supervision = CAMSelfSupervision(
    loss_weight=0.1,
    consistency_method="entropy",
)

# 5. è®­ç»ƒå™¨
trainer = MultimodalTrainer(
    model=model,
    criterion=nn.CrossEntropyLoss(),
    optimizer=torch.optim.Adam(model.parameters()),
    attention_supervision=attention_supervision,  # ä¼ å…¥ç›‘ç£æ¨¡å—
    config=config.training,
)

# 6. è®­ç»ƒ
trainer.fit(train_loader, val_loader)
```

#### 7. æ·»åŠ å•å…ƒæµ‹è¯•

```python
# tests/test_attention_supervision.py
import pytest
import torch
from med_core.attention_supervision import CAMSelfSupervision, generate_cam

def test_cam_generation():
    """æµ‹è¯• CAM ç”Ÿæˆ"""
    B, C, H, W = 2, 512, 16, 16
    num_classes = 2
    
    feature_maps = torch.randn(B, C, H, W)
    classifier_weights = torch.randn(num_classes, C)
    
    cam = generate_cam(feature_maps, classifier_weights)
    
    assert cam.shape == (B, H, W)
    assert cam.min() >= 0 and cam.max() <= 1

def test_cam_supervision():
    """æµ‹è¯• CAM ç›‘ç£"""
    supervision = CAMSelfSupervision(loss_weight=0.1)
    
    attention = torch.randn(2, 16, 16)
    features = torch.randn(2, 512, 16, 16)
    classifier_weights = torch.randn(2, 512)
    
    loss_result = supervision(
        attention_weights=attention,
        features=features,
        classifier_weights=classifier_weights,
    )
    
    assert loss_result.total_loss.requires_grad
    assert "consistency" in loss_result.components
```

---

## ðŸ“ æ€»ç»“

### å½“å‰çŠ¶æ€

| æ–¹é¢ | çŠ¶æ€ | è¯„åˆ† |
|------|------|------|
| ä»£ç è´¨é‡ | âœ… é«˜ | 9/10 |
| æž¶æž„è®¾è®¡ | âœ… è‰¯å¥½ | 8/10 |
| ä¸ŽçŽ°æœ‰æ¡†æž¶é›†æˆ | âŒ å¤±è´¥ | 2/10 |
| å¯ç”¨æ€§ | âŒ ä¸å¯ç”¨ | 1/10 |
| æ–‡æ¡£è´¨é‡ | âœ… é«˜ | 9/10 |
| **æ€»ä½“è¯„åˆ†** | âš ï¸ éœ€è¦ä¿®å¤ | **5/10** |

### æ ¸å¿ƒé—®é¢˜æ€»ç»“

1. **æž¶æž„ä¸åŒ¹é…** - çŽ°æœ‰æ¨¡åž‹ä¸è¿”å›žæ³¨æ„åŠ›æƒé‡
2. **é›†æˆç¼ºå¤±** - æ²¡æœ‰ä¿®æ”¹è®­ç»ƒå™¨æ¥ä½¿ç”¨æ³¨æ„åŠ›ç›‘ç£
3. **CAM æ–¹æ³•å‡è®¾é”™è¯¯** - å‡è®¾ç‰¹å¾æœªæ± åŒ–ï¼Œä½†å®žé™…å·²æ± åŒ–
4. **é…ç½®ç³»ç»Ÿå†—ä½™** - åˆ›å»ºäº†å¹³è¡Œçš„é…ç½®ç±»
5. **æ„å¤–æ–‡ä»¶** - æäº¤äº† 4.4MB çš„ zod æ–‡ä»¶
6. **åŠŸèƒ½é‡å¤** - ä¸ŽçŽ°æœ‰ CBAM/SE/ECA å…³ç³»ä¸æ¸…

### ä¿®å¤ä¼˜å…ˆçº§

**å¿…é¡»ä¿®å¤ï¼ˆé˜»å¡žæ€§ï¼‰**:
1. â— ç§»é™¤ zod æ–‡ä»¶
2. â— ä¿®æ”¹æ¨¡åž‹æž¶æž„è¿”å›žæ³¨æ„åŠ›æƒé‡
3. â— é›†æˆåˆ°è®­ç»ƒå™¨

**åº”è¯¥ä¿®å¤ï¼ˆåŠŸèƒ½æ€§ï¼‰**:
4. ä¿®å¤ CAM æ–¹æ³•é€‚é…çŽ°æœ‰æž¶æž„
5. æ•´åˆé…ç½®ç³»ç»Ÿ

**å»ºè®®ä¿®å¤ï¼ˆæ”¹è¿›æ€§ï¼‰**:
6. æ·»åŠ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
7. æ·»åŠ å•å…ƒæµ‹è¯•

### æœ€ç»ˆå»ºè®®

**é€‰é¡¹ A: é‡æž„åŽä¿ç•™**
- æŒ‰ç…§ä¸Šè¿°ä¿®å¤å»ºè®®è¿›è¡Œé‡å¤§ä¿®æ”¹
- é¢„è®¡å·¥ä½œé‡: 2-3 å¤©
- ä¿®å¤åŽå¯ä»¥æ­£å¸¸ä½¿ç”¨

**é€‰é¡¹ B: å›žæ»šæ­¤æäº¤**
- å›žæ»š commit cd3ebce
- é‡æ–°è®¾è®¡ï¼Œå…ˆä¿®æ”¹æ¨¡åž‹æž¶æž„ï¼Œå†å®žçŽ°æ³¨æ„åŠ›ç›‘ç£
- é¢„è®¡å·¥ä½œé‡: 3-4 å¤©ï¼ˆä»Žå¤´å¼€å§‹ï¼‰

**æŽ¨è**: **é€‰é¡¹ A**ï¼Œå› ä¸ºä»£ç è´¨é‡é«˜ï¼Œåªæ˜¯é›†æˆå·¥ä½œç¼ºå¤±ã€‚

---

## ðŸŽ¯ è¡ŒåŠ¨è®¡åˆ’

### ç«‹å³è¡ŒåŠ¨ï¼ˆä»Šå¤©ï¼‰

1. **ç§»é™¤ zod æ–‡ä»¶**
   ```bash
   git rm zod
   git commit --amend --no-edit
   ```

2. **åˆ›å»ºä¿®å¤åˆ†æ”¯**
   ```bash
   git checkout -b fix/attention-supervision-integration
   ```

### çŸ­æœŸè¡ŒåŠ¨ï¼ˆæœ¬å‘¨ï¼‰

3. **ä¿®æ”¹æ¨¡åž‹æž¶æž„** - ä½¿å…¶è¿”å›žæ³¨æ„åŠ›æƒé‡
4. **é›†æˆåˆ°è®­ç»ƒå™¨** - ä¿®æ”¹ `MultimodalTrainer`
5. **ä¿®å¤ CAM æ–¹æ³•** - é€‚é…çŽ°æœ‰æž¶æž„
6. **æ•´åˆé…ç½®ç³»ç»Ÿ** - æ‰©å±•çŽ°æœ‰é…ç½®ç±»

### ä¸­æœŸè¡ŒåŠ¨ï¼ˆä¸‹å‘¨ï¼‰

7. **æ·»åŠ ä½¿ç”¨ç¤ºä¾‹** - å®Œæ•´çš„ç«¯åˆ°ç«¯ç¤ºä¾‹
8. **æ·»åŠ å•å…ƒæµ‹è¯•** - è¦†ç›–æ‰€æœ‰ç›‘ç£æ–¹æ³•
9. **æ›´æ–°æ–‡æ¡£** - ä¿®æ­£ç¤ºä¾‹ä»£ç 
10. **æ€§èƒ½æµ‹è¯•** - éªŒè¯è®­ç»ƒé€Ÿåº¦å½±å“

---

**å®¡æŸ¥å®Œæˆæ—¥æœŸ**: 2026-02-13  
**ä¸‹æ¬¡å®¡æŸ¥**: ä¿®å¤å®ŒæˆåŽ
